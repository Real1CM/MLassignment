{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWVgLHirRfldXWBXhMnbQZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Real1CM/MLassignment/blob/main/%E4%BD%9C%E4%B8%9A5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "任务一"
      ],
      "metadata": {
        "id": "2NnO9IYGRU17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import numpy as np\n",
        "import struct\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "BPbDuGyaQSaL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MnistDataset(Dataset):\n",
        "    def __init__(self,mnist_idx_path,opt):\n",
        "        code2type = {0x08: 'B', 0x09: 'b', 0x0B: 'h', 0x0c: 'i', 0x0D: 'f', 0x0E: 'd'}\n",
        "        self.transform = transforms.Compose([\n",
        "                                     transforms.Resize(opt.imageSize),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5,), (0.5,)),\n",
        "                                 ])\n",
        "        with open(mnist_idx_path, 'rb') as f:\n",
        "            buff = f.read()\n",
        "            offset = 0\n",
        "            fmt = '>HBB'  # 格式定义，>表示高位在前，I表示4字节整数\n",
        "            _, dcode, dimslen = struct.unpack_from(fmt, buff, offset)\n",
        "            offset += struct.calcsize(fmt)\n",
        "\n",
        "            fmt = '>{}I'.format(dimslen)\n",
        "            shapes = struct.unpack_from(fmt, buff, offset)\n",
        "            offset += struct.calcsize(fmt)\n",
        "\n",
        "            fmt = '>' + str(np.prod(shapes)) + code2type[dcode]\n",
        "            matrix = struct.unpack_from(fmt, buff, offset)\n",
        "            self.images = np.reshape(matrix, shapes).astype(code2type[dcode])\n",
        "            self.len = shapes[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = self.images[index,...]\n",
        "        img = Image.fromarray(img, mode=\"L\")\n",
        "        img = self.transform(img)\n",
        "        return img\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n"
      ],
      "metadata": {
        "id": "as_iYjYhQosi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Opt:\n",
        "    dataroot='./'\n",
        "    batchSize=16\n",
        "    imageSize=64\n",
        "    nz=10 #size of the latent z vector\n",
        "    nc=1\n",
        "    ngf=32 #netG channels\n",
        "    ndf=32\n",
        "    epochs=500 #'number of epochs to train for'\n",
        "    lr=0.0002\n",
        "    beta1=0.5\n",
        "    netG=''#./netG.pth'\n",
        "    netD=''#./netD.pth'\n",
        "    outf='./'\n",
        "    manualSeed = 1000"
      ],
      "metadata": {
        "id": "hSeNOFccTJJL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        torch.nn.init.normal_(m.weight, 1.0, 0.02)\n",
        "        torch.nn.init.zeros_(m.bias)"
      ],
      "metadata": {
        "id": "ReVFMMjITOJb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self,nz,nc,ngf):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (nc) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.main(input)\n",
        "        return output"
      ],
      "metadata": {
        "id": "EY-3Fk5hTRnx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,nc,ndf):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # input is (nc) x 64 x 64\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.main(input)\n",
        "        return output.view(-1, 1).squeeze(1)"
      ],
      "metadata": {
        "id": "5epgK17fTVYD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    opt = Opt()\n",
        "\n",
        "    if opt.manualSeed is None:\n",
        "        opt.manualSeed = random.randint(1, 10000)\n",
        "    print(\"Random Seed: \", opt.manualSeed)\n",
        "    random.seed(opt.manualSeed)\n",
        "    torch.manual_seed(opt.manualSeed)\n",
        "\n",
        "    dataset = MnistDataset('./t10k-images-idx3-ubyte',opt)\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=opt.batchSize,\n",
        "                                             shuffle=True, num_workers=0)\n",
        "\n",
        "    netG = Generator(opt.nz, opt.nc, opt.ngf)\n",
        "    netG.apply(weights_init)\n",
        "    if opt.netG != '':\n",
        "        netG.load_state_dict(torch.load(opt.netG))\n",
        "    # print(netG)\n",
        "\n",
        "    netD = Discriminator(opt.nc, opt.ndf)\n",
        "    netD.apply(weights_init)\n",
        "    if opt.netD != '':\n",
        "        netD.load_state_dict(torch.load(opt.netD))\n",
        "    # print(netD)\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    fixed_noise = torch.randn(opt.batchSize, opt.nz, 1, 1)\n",
        "    real_label = 1\n",
        "    fake_label = 0\n",
        "\n",
        "    # setup optimizer\n",
        "    optimizerD = optim.Adam(netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
        "    optimizerG = optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
        "\n",
        "    for epoch in range(opt.epochs):\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "            ############################\n",
        "            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "            ###########################\n",
        "            # train with real\n",
        "            netD.zero_grad()\n",
        "            real_cpu = data\n",
        "            batch_size = real_cpu.size(0)\n",
        "            label = torch.full((batch_size,), real_label,\n",
        "                               dtype=real_cpu.dtype)\n",
        "\n",
        "            output = netD(real_cpu)\n",
        "            errD_real = criterion(output, label)\n",
        "            errD_real.backward()\n",
        "            D_x = output.mean().item()\n",
        "\n",
        "            # train with fake\n",
        "            noise = torch.randn(batch_size, opt.nz, 1, 1)\n",
        "            fake = netG(noise)\n",
        "            label.fill_(fake_label)\n",
        "            output = netD(fake.detach())\n",
        "            errD_fake = criterion(output, label)\n",
        "            errD_fake.backward()\n",
        "            D_G_z1 = output.mean().item()\n",
        "            errD = errD_real + errD_fake\n",
        "            optimizerD.step()\n",
        "\n",
        "            ############################\n",
        "            # (2) Update G network: maximize log(D(G(z)))\n",
        "            ###########################\n",
        "            netG.zero_grad()\n",
        "            label.fill_(real_label)  # fake labels are real for generator cost\n",
        "            output = netD(fake)\n",
        "            errG = criterion(output, label)\n",
        "            errG.backward()\n",
        "            D_G_z2 = output.mean().item()\n",
        "            optimizerG.step()\n",
        "\n",
        "            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f' %\n",
        "      (epoch, opt.epochs, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "            if i % 100 == 0:\n",
        "                vutils.save_image(real_cpu,\n",
        "                                  '%s/real_samples.png' % opt.outf,\n",
        "                                  normalize=True)\n",
        "                fake = netG(fixed_noise)\n",
        "                vutils.save_image(fake.detach(),\n",
        "                                  '%s/fake_samples_epoch_%03d.png' %\n",
        "                                 (opt.outf, epoch),\n",
        "                                  normalize=True)\n",
        "        # do checkpointing\n",
        "        torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (opt.outf, epoch))\n",
        "        torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (opt.outf, epoch))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ArqiIUUoTZdz",
        "outputId": "d59ad38b-6e08-4259-bd62-542bba7ae79c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:  1000\n",
            "[0/500][0/625] Loss_D: 1.7040 Loss_G: 2.3435 D(x): 0.7328 D(G(z)): 0.7092 / 0.1342\n",
            "[0/500][1/625] Loss_D: 1.1078 Loss_G: 2.7100 D(x): 0.8810 D(G(z)): 0.6052 / 0.1048\n",
            "[0/500][2/625] Loss_D: 0.7086 Loss_G: 2.9941 D(x): 0.9079 D(G(z)): 0.4117 / 0.0980\n",
            "[0/500][3/625] Loss_D: 0.4218 Loss_G: 3.3534 D(x): 0.9573 D(G(z)): 0.2987 / 0.0454\n",
            "[0/500][4/625] Loss_D: 0.3911 Loss_G: 3.2711 D(x): 0.9391 D(G(z)): 0.2612 / 0.0552\n",
            "[0/500][5/625] Loss_D: 0.3618 Loss_G: 3.3519 D(x): 0.9383 D(G(z)): 0.2398 / 0.0471\n",
            "[0/500][6/625] Loss_D: 0.3717 Loss_G: 3.3589 D(x): 0.9557 D(G(z)): 0.2717 / 0.0450\n",
            "[0/500][7/625] Loss_D: 0.2760 Loss_G: 3.4603 D(x): 0.9581 D(G(z)): 0.2040 / 0.0401\n",
            "[0/500][8/625] Loss_D: 0.4045 Loss_G: 3.5928 D(x): 0.9459 D(G(z)): 0.2646 / 0.0440\n",
            "[0/500][9/625] Loss_D: 0.2720 Loss_G: 3.7767 D(x): 0.9298 D(G(z)): 0.1683 / 0.0307\n",
            "[0/500][10/625] Loss_D: 0.2820 Loss_G: 3.6463 D(x): 0.9120 D(G(z)): 0.1528 / 0.0325\n",
            "[0/500][11/625] Loss_D: 0.2860 Loss_G: 3.7402 D(x): 0.9323 D(G(z)): 0.1777 / 0.0284\n",
            "[0/500][12/625] Loss_D: 0.1590 Loss_G: 3.9344 D(x): 0.9864 D(G(z)): 0.1308 / 0.0266\n",
            "[0/500][13/625] Loss_D: 0.2164 Loss_G: 4.2842 D(x): 0.9695 D(G(z)): 0.1560 / 0.0196\n",
            "[0/500][14/625] Loss_D: 0.1974 Loss_G: 4.3110 D(x): 0.9630 D(G(z)): 0.1417 / 0.0174\n",
            "[0/500][15/625] Loss_D: 0.1817 Loss_G: 4.1661 D(x): 0.9303 D(G(z)): 0.0947 / 0.0187\n",
            "[0/500][16/625] Loss_D: 0.2174 Loss_G: 4.2001 D(x): 0.9341 D(G(z)): 0.1279 / 0.0186\n",
            "[0/500][17/625] Loss_D: 0.0978 Loss_G: 4.3183 D(x): 0.9692 D(G(z)): 0.0625 / 0.0199\n",
            "[0/500][18/625] Loss_D: 0.1622 Loss_G: 4.0455 D(x): 0.9632 D(G(z)): 0.1137 / 0.0209\n",
            "[0/500][19/625] Loss_D: 0.1616 Loss_G: 4.4980 D(x): 0.9875 D(G(z)): 0.1317 / 0.0139\n",
            "[0/500][20/625] Loss_D: 0.1565 Loss_G: 4.4224 D(x): 0.9476 D(G(z)): 0.0930 / 0.0128\n",
            "[0/500][21/625] Loss_D: 0.2155 Loss_G: 4.4430 D(x): 0.9480 D(G(z)): 0.1218 / 0.0159\n",
            "[0/500][22/625] Loss_D: 0.1847 Loss_G: 4.7668 D(x): 0.9805 D(G(z)): 0.1482 / 0.0126\n",
            "[0/500][23/625] Loss_D: 0.1786 Loss_G: 4.4329 D(x): 0.9130 D(G(z)): 0.0752 / 0.0149\n",
            "[0/500][24/625] Loss_D: 0.1854 Loss_G: 4.4697 D(x): 0.9433 D(G(z)): 0.1135 / 0.0130\n",
            "[0/500][25/625] Loss_D: 0.2315 Loss_G: 5.8262 D(x): 0.9776 D(G(z)): 0.1718 / 0.0046\n",
            "[0/500][26/625] Loss_D: 0.2054 Loss_G: 4.7689 D(x): 0.8707 D(G(z)): 0.0365 / 0.0113\n",
            "[0/500][27/625] Loss_D: 0.0985 Loss_G: 4.9860 D(x): 0.9932 D(G(z)): 0.0863 / 0.0083\n",
            "[0/500][28/625] Loss_D: 0.1181 Loss_G: 5.6421 D(x): 0.9859 D(G(z)): 0.0970 / 0.0042\n",
            "[0/500][29/625] Loss_D: 0.0807 Loss_G: 5.4602 D(x): 0.9637 D(G(z)): 0.0418 / 0.0054\n",
            "[0/500][30/625] Loss_D: 0.0719 Loss_G: 4.8673 D(x): 0.9693 D(G(z)): 0.0387 / 0.0093\n",
            "[0/500][31/625] Loss_D: 0.1888 Loss_G: 5.7600 D(x): 0.9573 D(G(z)): 0.1305 / 0.0038\n",
            "[0/500][32/625] Loss_D: 0.2076 Loss_G: 4.2394 D(x): 0.8816 D(G(z)): 0.0482 / 0.0170\n",
            "[0/500][33/625] Loss_D: 0.1756 Loss_G: 6.7296 D(x): 0.9949 D(G(z)): 0.1504 / 0.0015\n",
            "[0/500][34/625] Loss_D: 0.0838 Loss_G: 6.1057 D(x): 0.9520 D(G(z)): 0.0324 / 0.0028\n",
            "[0/500][35/625] Loss_D: 0.0475 Loss_G: 5.5756 D(x): 0.9836 D(G(z)): 0.0300 / 0.0053\n",
            "[0/500][36/625] Loss_D: 0.0973 Loss_G: 5.5784 D(x): 0.9806 D(G(z)): 0.0716 / 0.0051\n",
            "[0/500][37/625] Loss_D: 0.0845 Loss_G: 5.7403 D(x): 0.9767 D(G(z)): 0.0581 / 0.0038\n",
            "[0/500][38/625] Loss_D: 0.1184 Loss_G: 5.6650 D(x): 0.9531 D(G(z)): 0.0661 / 0.0040\n",
            "[0/500][39/625] Loss_D: 0.1015 Loss_G: 5.5677 D(x): 0.9470 D(G(z)): 0.0400 / 0.0058\n",
            "[0/500][40/625] Loss_D: 0.0651 Loss_G: 5.9397 D(x): 0.9952 D(G(z)): 0.0573 / 0.0040\n",
            "[0/500][41/625] Loss_D: 0.0639 Loss_G: 6.2762 D(x): 0.9863 D(G(z)): 0.0481 / 0.0028\n",
            "[0/500][42/625] Loss_D: 0.0924 Loss_G: 4.8727 D(x): 0.9411 D(G(z)): 0.0244 / 0.0106\n",
            "[0/500][43/625] Loss_D: 0.1248 Loss_G: 7.0288 D(x): 0.9902 D(G(z)): 0.1058 / 0.0012\n",
            "[0/500][44/625] Loss_D: 0.0371 Loss_G: 6.9049 D(x): 0.9813 D(G(z)): 0.0178 / 0.0016\n",
            "[0/500][45/625] Loss_D: 0.0575 Loss_G: 5.3421 D(x): 0.9593 D(G(z)): 0.0128 / 0.0065\n",
            "[0/500][46/625] Loss_D: 0.0541 Loss_G: 5.3217 D(x): 0.9907 D(G(z)): 0.0428 / 0.0061\n",
            "[0/500][47/625] Loss_D: 0.0610 Loss_G: 5.6905 D(x): 0.9859 D(G(z)): 0.0451 / 0.0041\n",
            "[0/500][48/625] Loss_D: 0.1003 Loss_G: 6.1409 D(x): 0.9651 D(G(z)): 0.0601 / 0.0027\n",
            "[0/500][49/625] Loss_D: 0.0528 Loss_G: 6.0834 D(x): 0.9751 D(G(z)): 0.0258 / 0.0027\n",
            "[0/500][50/625] Loss_D: 0.0352 Loss_G: 5.8232 D(x): 0.9849 D(G(z)): 0.0196 / 0.0039\n",
            "[0/500][51/625] Loss_D: 0.0443 Loss_G: 6.3869 D(x): 0.9954 D(G(z)): 0.0383 / 0.0022\n",
            "[0/500][52/625] Loss_D: 0.0582 Loss_G: 6.1090 D(x): 0.9753 D(G(z)): 0.0315 / 0.0028\n",
            "[0/500][53/625] Loss_D: 0.0314 Loss_G: 6.0801 D(x): 0.9855 D(G(z)): 0.0161 / 0.0036\n",
            "[0/500][54/625] Loss_D: 0.0485 Loss_G: 5.6381 D(x): 0.9809 D(G(z)): 0.0282 / 0.0047\n",
            "[0/500][55/625] Loss_D: 0.0417 Loss_G: 6.2282 D(x): 0.9940 D(G(z)): 0.0347 / 0.0025\n",
            "[0/500][56/625] Loss_D: 0.0336 Loss_G: 6.0109 D(x): 0.9836 D(G(z)): 0.0162 / 0.0029\n",
            "[0/500][57/625] Loss_D: 0.0497 Loss_G: 5.2454 D(x): 0.9667 D(G(z)): 0.0135 / 0.0086\n",
            "[0/500][58/625] Loss_D: 0.0618 Loss_G: 6.4031 D(x): 0.9934 D(G(z)): 0.0529 / 0.0022\n",
            "[0/500][59/625] Loss_D: 0.0151 Loss_G: 6.8250 D(x): 0.9946 D(G(z)): 0.0095 / 0.0014\n",
            "[0/500][60/625] Loss_D: 0.0341 Loss_G: 5.9438 D(x): 0.9782 D(G(z)): 0.0113 / 0.0038\n",
            "[0/500][61/625] Loss_D: 0.0226 Loss_G: 5.8117 D(x): 0.9913 D(G(z)): 0.0135 / 0.0045\n",
            "[0/500][62/625] Loss_D: 0.0250 Loss_G: 5.7302 D(x): 0.9923 D(G(z)): 0.0168 / 0.0040\n",
            "[0/500][63/625] Loss_D: 0.0241 Loss_G: 6.1157 D(x): 0.9967 D(G(z)): 0.0205 / 0.0026\n",
            "[0/500][64/625] Loss_D: 0.0198 Loss_G: 6.1422 D(x): 0.9946 D(G(z)): 0.0143 / 0.0024\n",
            "[0/500][65/625] Loss_D: 0.0207 Loss_G: 5.9379 D(x): 0.9866 D(G(z)): 0.0071 / 0.0033\n",
            "[0/500][66/625] Loss_D: 0.0228 Loss_G: 5.8597 D(x): 0.9950 D(G(z)): 0.0175 / 0.0037\n",
            "[0/500][67/625] Loss_D: 0.0317 Loss_G: 6.6711 D(x): 0.9957 D(G(z)): 0.0263 / 0.0015\n",
            "[0/500][68/625] Loss_D: 0.0441 Loss_G: 5.4784 D(x): 0.9668 D(G(z)): 0.0093 / 0.0048\n",
            "[0/500][69/625] Loss_D: 0.0254 Loss_G: 5.8001 D(x): 0.9949 D(G(z)): 0.0200 / 0.0037\n",
            "[0/500][70/625] Loss_D: 0.0205 Loss_G: 6.3350 D(x): 0.9977 D(G(z)): 0.0179 / 0.0019\n",
            "[0/500][71/625] Loss_D: 0.0127 Loss_G: 6.6785 D(x): 0.9948 D(G(z)): 0.0073 / 0.0017\n",
            "[0/500][72/625] Loss_D: 0.0122 Loss_G: 6.3804 D(x): 0.9961 D(G(z)): 0.0082 / 0.0022\n",
            "[0/500][73/625] Loss_D: 0.0192 Loss_G: 6.3790 D(x): 0.9981 D(G(z)): 0.0170 / 0.0020\n",
            "[0/500][74/625] Loss_D: 0.0184 Loss_G: 6.3703 D(x): 0.9891 D(G(z)): 0.0073 / 0.0023\n",
            "[0/500][75/625] Loss_D: 0.0247 Loss_G: 5.8752 D(x): 0.9871 D(G(z)): 0.0113 / 0.0037\n",
            "[0/500][76/625] Loss_D: 0.0218 Loss_G: 6.5179 D(x): 0.9970 D(G(z)): 0.0186 / 0.0019\n",
            "[0/500][77/625] Loss_D: 0.0204 Loss_G: 6.7156 D(x): 0.9902 D(G(z)): 0.0102 / 0.0017\n",
            "[0/500][78/625] Loss_D: 0.0138 Loss_G: 6.4431 D(x): 0.9939 D(G(z)): 0.0076 / 0.0020\n",
            "[0/500][79/625] Loss_D: 0.0150 Loss_G: 6.4580 D(x): 0.9915 D(G(z)): 0.0064 / 0.0025\n",
            "[0/500][80/625] Loss_D: 0.0353 Loss_G: 7.0221 D(x): 0.9904 D(G(z)): 0.0248 / 0.0012\n",
            "[0/500][81/625] Loss_D: 0.0298 Loss_G: 6.0756 D(x): 0.9784 D(G(z)): 0.0069 / 0.0030\n",
            "[0/500][82/625] Loss_D: 0.0283 Loss_G: 6.2569 D(x): 0.9876 D(G(z)): 0.0150 / 0.0022\n",
            "[0/500][83/625] Loss_D: 0.0163 Loss_G: 7.5933 D(x): 0.9978 D(G(z)): 0.0140 / 0.0006\n",
            "[0/500][84/625] Loss_D: 0.0132 Loss_G: 7.1104 D(x): 0.9903 D(G(z)): 0.0030 / 0.0010\n",
            "[0/500][85/625] Loss_D: 0.0136 Loss_G: 6.3127 D(x): 0.9919 D(G(z)): 0.0053 / 0.0025\n",
            "[0/500][86/625] Loss_D: 0.0182 Loss_G: 7.3440 D(x): 0.9983 D(G(z)): 0.0163 / 0.0007\n",
            "[0/500][87/625] Loss_D: 0.0338 Loss_G: 4.6922 D(x): 0.9707 D(G(z)): 0.0024 / 0.0101\n",
            "[0/500][88/625] Loss_D: 0.0816 Loss_G: 14.1869 D(x): 0.9994 D(G(z)): 0.0768 / 0.0000\n",
            "[0/500][89/625] Loss_D: 0.9507 Loss_G: 0.0023 D(x): 0.4385 D(G(z)): 0.0000 / 0.9977\n",
            "[0/500][90/625] Loss_D: 6.0382 Loss_G: 18.4381 D(x): 0.9999 D(G(z)): 0.9961 / 0.0000\n",
            "[0/500][91/625] Loss_D: 6.1204 Loss_G: 14.5375 D(x): 0.0056 D(G(z)): 0.0000 / 0.0000\n",
            "[0/500][92/625] Loss_D: 0.1561 Loss_G: 11.0537 D(x): 0.8734 D(G(z)): 0.0000 / 0.0000\n",
            "[0/500][93/625] Loss_D: 0.0057 Loss_G: 5.9510 D(x): 0.9958 D(G(z)): 0.0014 / 0.0038\n",
            "[0/500][94/625] Loss_D: 0.8227 Loss_G: 9.5778 D(x): 0.9606 D(G(z)): 0.4873 / 0.0001\n",
            "[0/500][95/625] Loss_D: 0.0479 Loss_G: 8.7408 D(x): 0.9704 D(G(z)): 0.0160 / 0.0002\n",
            "[0/500][96/625] Loss_D: 0.2827 Loss_G: 5.8678 D(x): 0.8405 D(G(z)): 0.0138 / 0.0042\n",
            "[0/500][97/625] Loss_D: 0.1381 Loss_G: 5.7780 D(x): 0.9744 D(G(z)): 0.1032 / 0.0049\n",
            "[0/500][98/625] Loss_D: 0.1198 Loss_G: 6.1145 D(x): 0.9503 D(G(z)): 0.0631 / 0.0034\n",
            "[0/500][99/625] Loss_D: 0.0822 Loss_G: 6.0480 D(x): 0.9668 D(G(z)): 0.0452 / 0.0040\n",
            "[0/500][100/625] Loss_D: 0.1196 Loss_G: 5.7055 D(x): 0.9342 D(G(z)): 0.0459 / 0.0039\n",
            "[0/500][101/625] Loss_D: 0.1268 Loss_G: 7.1705 D(x): 0.9800 D(G(z)): 0.0992 / 0.0013\n",
            "[0/500][102/625] Loss_D: 0.1428 Loss_G: 5.8916 D(x): 0.8969 D(G(z)): 0.0227 / 0.0037\n",
            "[0/500][103/625] Loss_D: 0.1624 Loss_G: 6.8256 D(x): 0.9526 D(G(z)): 0.0988 / 0.0019\n",
            "[0/500][104/625] Loss_D: 0.1027 Loss_G: 6.7728 D(x): 0.9576 D(G(z)): 0.0482 / 0.0018\n",
            "[0/500][105/625] Loss_D: 0.1220 Loss_G: 6.9620 D(x): 0.9641 D(G(z)): 0.0791 / 0.0015\n",
            "[0/500][106/625] Loss_D: 0.1226 Loss_G: 7.5841 D(x): 0.9624 D(G(z)): 0.0781 / 0.0007\n",
            "[0/500][107/625] Loss_D: 0.1799 Loss_G: 6.3206 D(x): 0.8913 D(G(z)): 0.0511 / 0.0023\n",
            "[0/500][108/625] Loss_D: 0.1892 Loss_G: 10.0815 D(x): 0.9798 D(G(z)): 0.1467 / 0.0001\n",
            "[0/500][109/625] Loss_D: 0.0366 Loss_G: 9.7949 D(x): 0.9666 D(G(z)): 0.0014 / 0.0001\n",
            "[0/500][110/625] Loss_D: 0.0501 Loss_G: 7.4089 D(x): 0.9547 D(G(z)): 0.0021 / 0.0007\n",
            "[0/500][111/625] Loss_D: 0.0703 Loss_G: 5.2364 D(x): 0.9631 D(G(z)): 0.0241 / 0.0065\n",
            "[0/500][112/625] Loss_D: 0.3161 Loss_G: 12.0573 D(x): 0.9678 D(G(z)): 0.2297 / 0.0000\n",
            "[0/500][113/625] Loss_D: 0.0763 Loss_G: 12.7694 D(x): 0.9307 D(G(z)): 0.0001 / 0.0000\n",
            "[0/500][114/625] Loss_D: 0.0698 Loss_G: 11.2733 D(x): 0.9357 D(G(z)): 0.0000 / 0.0000\n",
            "[0/500][115/625] Loss_D: 0.0198 Loss_G: 9.5420 D(x): 0.9814 D(G(z)): 0.0001 / 0.0001\n",
            "[0/500][116/625] Loss_D: 0.0102 Loss_G: 6.3907 D(x): 0.9927 D(G(z)): 0.0028 / 0.0024\n",
            "[0/500][117/625] Loss_D: 0.0448 Loss_G: 5.4545 D(x): 0.9978 D(G(z)): 0.0414 / 0.0055\n",
            "[0/500][118/625] Loss_D: 0.1693 Loss_G: 9.5964 D(x): 0.9939 D(G(z)): 0.1464 / 0.0001\n",
            "[0/500][119/625] Loss_D: 0.0514 Loss_G: 10.3009 D(x): 0.9535 D(G(z)): 0.0006 / 0.0000\n",
            "[0/500][120/625] Loss_D: 0.0858 Loss_G: 8.8484 D(x): 0.9277 D(G(z)): 0.0003 / 0.0002\n",
            "[0/500][121/625] Loss_D: 0.0117 Loss_G: 7.2444 D(x): 0.9895 D(G(z)): 0.0010 / 0.0008\n",
            "[0/500][122/625] Loss_D: 0.0147 Loss_G: 5.3633 D(x): 0.9946 D(G(z)): 0.0092 / 0.0058\n",
            "[0/500][123/625] Loss_D: 0.0516 Loss_G: 5.9079 D(x): 0.9977 D(G(z)): 0.0476 / 0.0037\n",
            "[0/500][124/625] Loss_D: 0.0750 Loss_G: 7.5064 D(x): 0.9886 D(G(z)): 0.0593 / 0.0007\n",
            "[0/500][125/625] Loss_D: 0.0182 Loss_G: 7.8611 D(x): 0.9883 D(G(z)): 0.0062 / 0.0006\n",
            "[0/500][126/625] Loss_D: 0.0325 Loss_G: 6.7130 D(x): 0.9741 D(G(z)): 0.0051 / 0.0018\n",
            "[0/500][127/625] Loss_D: 0.0325 Loss_G: 5.9348 D(x): 0.9860 D(G(z)): 0.0179 / 0.0048\n",
            "[0/500][128/625] Loss_D: 0.0517 Loss_G: 6.5581 D(x): 0.9912 D(G(z)): 0.0405 / 0.0017\n",
            "[0/500][129/625] Loss_D: 0.0566 Loss_G: 6.6753 D(x): 0.9745 D(G(z)): 0.0290 / 0.0016\n",
            "[0/500][130/625] Loss_D: 0.0614 Loss_G: 5.6027 D(x): 0.9545 D(G(z)): 0.0132 / 0.0045\n",
            "[0/500][131/625] Loss_D: 0.0460 Loss_G: 5.4380 D(x): 0.9830 D(G(z)): 0.0279 / 0.0053\n",
            "[0/500][132/625] Loss_D: 0.0541 Loss_G: 5.9882 D(x): 0.9801 D(G(z)): 0.0326 / 0.0028\n",
            "[0/500][133/625] Loss_D: 0.1882 Loss_G: 3.9015 D(x): 0.8906 D(G(z)): 0.0176 / 0.0226\n",
            "[0/500][134/625] Loss_D: 0.1824 Loss_G: 9.5499 D(x): 0.9967 D(G(z)): 0.1581 / 0.0001\n",
            "[0/500][135/625] Loss_D: 0.2381 Loss_G: 6.3704 D(x): 0.8068 D(G(z)): 0.0006 / 0.0028\n",
            "[0/500][136/625] Loss_D: 0.0122 Loss_G: 4.6435 D(x): 0.9948 D(G(z)): 0.0069 / 0.0111\n",
            "[0/500][137/625] Loss_D: 0.1363 Loss_G: 6.9842 D(x): 0.9983 D(G(z)): 0.1251 / 0.0020\n",
            "[0/500][138/625] Loss_D: 0.0089 Loss_G: 8.1495 D(x): 0.9952 D(G(z)): 0.0040 / 0.0005\n",
            "[0/500][139/625] Loss_D: 0.0910 Loss_G: 6.0228 D(x): 0.9244 D(G(z)): 0.0018 / 0.0028\n",
            "[0/500][140/625] Loss_D: 0.0332 Loss_G: 4.4249 D(x): 0.9855 D(G(z)): 0.0182 / 0.0138\n",
            "[0/500][141/625] Loss_D: 0.1152 Loss_G: 8.0112 D(x): 0.9979 D(G(z)): 0.1032 / 0.0005\n",
            "[0/500][142/625] Loss_D: 0.0412 Loss_G: 7.4667 D(x): 0.9638 D(G(z)): 0.0035 / 0.0010\n",
            "[0/500][143/625] Loss_D: 0.1328 Loss_G: 3.3202 D(x): 0.8939 D(G(z)): 0.0059 / 0.0483\n",
            "[0/500][144/625] Loss_D: 0.2544 Loss_G: 9.1432 D(x): 0.9926 D(G(z)): 0.2005 / 0.0001\n",
            "[0/500][145/625] Loss_D: 0.3731 Loss_G: 1.5848 D(x): 0.7364 D(G(z)): 0.0009 / 0.2834\n",
            "[0/500][146/625] Loss_D: 0.7743 Loss_G: 13.8241 D(x): 0.9978 D(G(z)): 0.4329 / 0.0000\n",
            "[0/500][147/625] Loss_D: 3.8164 Loss_G: 2.0906 D(x): 0.0597 D(G(z)): 0.0001 / 0.3320\n",
            "[0/500][148/625] Loss_D: 0.8769 Loss_G: 7.3874 D(x): 0.9999 D(G(z)): 0.4589 / 0.0018\n",
            "[0/500][149/625] Loss_D: 0.1552 Loss_G: 6.7593 D(x): 0.8863 D(G(z)): 0.0055 / 0.0057\n",
            "[0/500][150/625] Loss_D: 0.1088 Loss_G: 4.7113 D(x): 0.9147 D(G(z)): 0.0141 / 0.0326\n",
            "[0/500][151/625] Loss_D: 0.1350 Loss_G: 5.6724 D(x): 0.9908 D(G(z)): 0.0975 / 0.0052\n",
            "[0/500][152/625] Loss_D: 0.0452 Loss_G: 5.3733 D(x): 0.9817 D(G(z)): 0.0259 / 0.0071\n",
            "[0/500][153/625] Loss_D: 0.0721 Loss_G: 4.6806 D(x): 0.9646 D(G(z)): 0.0344 / 0.0191\n",
            "[0/500][154/625] Loss_D: 0.0625 Loss_G: 4.5154 D(x): 0.9729 D(G(z)): 0.0334 / 0.0198\n",
            "[0/500][155/625] Loss_D: 0.1363 Loss_G: 4.6286 D(x): 0.9647 D(G(z)): 0.0932 / 0.0121\n",
            "[0/500][156/625] Loss_D: 0.4168 Loss_G: 0.8021 D(x): 0.7470 D(G(z)): 0.0411 / 0.4709\n",
            "[0/500][157/625] Loss_D: 1.7436 Loss_G: 13.1038 D(x): 0.9997 D(G(z)): 0.7774 / 0.0000\n",
            "[0/500][158/625] Loss_D: 5.4538 Loss_G: 3.3364 D(x): 0.0085 D(G(z)): 0.0000 / 0.0564\n",
            "[0/500][159/625] Loss_D: 0.2663 Loss_G: 1.4736 D(x): 0.9974 D(G(z)): 0.2033 / 0.2858\n",
            "[0/500][160/625] Loss_D: 2.3724 Loss_G: 6.5563 D(x): 0.9998 D(G(z)): 0.7591 / 0.0039\n",
            "[0/500][161/625] Loss_D: 0.1711 Loss_G: 7.1827 D(x): 0.8668 D(G(z)): 0.0158 / 0.0027\n",
            "[0/500][162/625] Loss_D: 0.6946 Loss_G: 3.7947 D(x): 0.5432 D(G(z)): 0.0049 / 0.0386\n",
            "[0/500][163/625] Loss_D: 0.5894 Loss_G: 4.0552 D(x): 0.9707 D(G(z)): 0.3418 / 0.0320\n",
            "[0/500][164/625] Loss_D: 0.1623 Loss_G: 5.0808 D(x): 0.9616 D(G(z)): 0.1091 / 0.0092\n",
            "[0/500][165/625] Loss_D: 0.0670 Loss_G: 5.5250 D(x): 0.9521 D(G(z)): 0.0167 / 0.0072\n",
            "[0/500][166/625] Loss_D: 0.1016 Loss_G: 4.3974 D(x): 0.9292 D(G(z)): 0.0245 / 0.0195\n",
            "[0/500][167/625] Loss_D: 0.0763 Loss_G: 3.7029 D(x): 0.9769 D(G(z)): 0.0510 / 0.0301\n",
            "[0/500][168/625] Loss_D: 0.1692 Loss_G: 4.2463 D(x): 0.9632 D(G(z)): 0.1146 / 0.0224\n",
            "[0/500][169/625] Loss_D: 0.2193 Loss_G: 4.0908 D(x): 0.8895 D(G(z)): 0.0818 / 0.0199\n",
            "[0/500][170/625] Loss_D: 0.0988 Loss_G: 4.1553 D(x): 0.9597 D(G(z)): 0.0544 / 0.0189\n",
            "[0/500][171/625] Loss_D: 0.0986 Loss_G: 4.0935 D(x): 0.9511 D(G(z)): 0.0450 / 0.0213\n",
            "[0/500][172/625] Loss_D: 0.1243 Loss_G: 3.5554 D(x): 0.9253 D(G(z)): 0.0425 / 0.0381\n",
            "[0/500][173/625] Loss_D: 0.2069 Loss_G: 4.3543 D(x): 0.9695 D(G(z)): 0.1558 / 0.0166\n",
            "[0/500][174/625] Loss_D: 0.1548 Loss_G: 4.4350 D(x): 0.9287 D(G(z)): 0.0607 / 0.0139\n",
            "[0/500][175/625] Loss_D: 0.2460 Loss_G: 2.6887 D(x): 0.8210 D(G(z)): 0.0309 / 0.0718\n",
            "[0/500][176/625] Loss_D: 0.1871 Loss_G: 4.3572 D(x): 0.9852 D(G(z)): 0.1558 / 0.0142\n",
            "[0/500][177/625] Loss_D: 0.0889 Loss_G: 5.1622 D(x): 0.9739 D(G(z)): 0.0599 / 0.0069\n",
            "[0/500][178/625] Loss_D: 0.1181 Loss_G: 4.3945 D(x): 0.9109 D(G(z)): 0.0182 / 0.0151\n",
            "[0/500][179/625] Loss_D: 0.1246 Loss_G: 3.8251 D(x): 0.9428 D(G(z)): 0.0612 / 0.0241\n",
            "[0/500][180/625] Loss_D: 0.0897 Loss_G: 4.8717 D(x): 0.9834 D(G(z)): 0.0691 / 0.0097\n",
            "[0/500][181/625] Loss_D: 0.0932 Loss_G: 4.7410 D(x): 0.9428 D(G(z)): 0.0310 / 0.0114\n",
            "[0/500][182/625] Loss_D: 0.0742 Loss_G: 4.2077 D(x): 0.9521 D(G(z)): 0.0232 / 0.0162\n",
            "[0/500][183/625] Loss_D: 0.1001 Loss_G: 4.2815 D(x): 0.9585 D(G(z)): 0.0535 / 0.0175\n",
            "[0/500][184/625] Loss_D: 0.1038 Loss_G: 4.7015 D(x): 0.9575 D(G(z)): 0.0548 / 0.0117\n",
            "[0/500][185/625] Loss_D: 0.0761 Loss_G: 4.6673 D(x): 0.9561 D(G(z)): 0.0266 / 0.0108\n",
            "[0/500][186/625] Loss_D: 0.0627 Loss_G: 4.8544 D(x): 0.9789 D(G(z)): 0.0397 / 0.0089\n",
            "[0/500][187/625] Loss_D: 0.0524 Loss_G: 5.0996 D(x): 0.9826 D(G(z)): 0.0333 / 0.0082\n",
            "[0/500][188/625] Loss_D: 0.0550 Loss_G: 4.9308 D(x): 0.9778 D(G(z)): 0.0317 / 0.0088\n",
            "[0/500][189/625] Loss_D: 0.1515 Loss_G: 3.2415 D(x): 0.9035 D(G(z)): 0.0283 / 0.0435\n",
            "[0/500][190/625] Loss_D: 0.2845 Loss_G: 7.1125 D(x): 0.9878 D(G(z)): 0.2299 / 0.0012\n",
            "[0/500][191/625] Loss_D: 0.3539 Loss_G: 4.1671 D(x): 0.7742 D(G(z)): 0.0039 / 0.0184\n",
            "[0/500][192/625] Loss_D: 0.0849 Loss_G: 3.2101 D(x): 0.9793 D(G(z)): 0.0603 / 0.0465\n",
            "[0/500][193/625] Loss_D: 0.4180 Loss_G: 8.1478 D(x): 0.9906 D(G(z)): 0.3141 / 0.0005\n",
            "[0/500][194/625] Loss_D: 0.3893 Loss_G: 4.7446 D(x): 0.7399 D(G(z)): 0.0055 / 0.0146\n",
            "[0/500][195/625] Loss_D: 0.1241 Loss_G: 4.1372 D(x): 0.9884 D(G(z)): 0.0991 / 0.0246\n",
            "[0/500][196/625] Loss_D: 0.1134 Loss_G: 4.9879 D(x): 0.9897 D(G(z)): 0.0948 / 0.0095\n",
            "[0/500][197/625] Loss_D: 0.1327 Loss_G: 4.4208 D(x): 0.9272 D(G(z)): 0.0494 / 0.0164\n",
            "[0/500][198/625] Loss_D: 0.1690 Loss_G: 3.9802 D(x): 0.9287 D(G(z)): 0.0831 / 0.0235\n",
            "[0/500][199/625] Loss_D: 0.2217 Loss_G: 4.2689 D(x): 0.9122 D(G(z)): 0.1112 / 0.0213\n",
            "[0/500][200/625] Loss_D: 0.1197 Loss_G: 3.7073 D(x): 0.9244 D(G(z)): 0.0377 / 0.0269\n",
            "[0/500][201/625] Loss_D: 0.1230 Loss_G: 4.8568 D(x): 0.9774 D(G(z)): 0.0925 / 0.0115\n",
            "[0/500][202/625] Loss_D: 0.2376 Loss_G: 1.9199 D(x): 0.8402 D(G(z)): 0.0465 / 0.1727\n",
            "[0/500][203/625] Loss_D: 0.5254 Loss_G: 11.2075 D(x): 0.9951 D(G(z)): 0.3853 / 0.0000\n",
            "[0/500][204/625] Loss_D: 3.5214 Loss_G: 0.1154 D(x): 0.0784 D(G(z)): 0.0001 / 0.8944\n",
            "[0/500][205/625] Loss_D: 2.9099 Loss_G: 9.1804 D(x): 0.9987 D(G(z)): 0.9252 / 0.0002\n",
            "[0/500][206/625] Loss_D: 1.5283 Loss_G: 5.2242 D(x): 0.3470 D(G(z)): 0.0012 / 0.0125\n",
            "[0/500][207/625] Loss_D: 0.1984 Loss_G: 2.7251 D(x): 0.8675 D(G(z)): 0.0337 / 0.1435\n",
            "[0/500][208/625] Loss_D: 0.6339 Loss_G: 3.8153 D(x): 0.9701 D(G(z)): 0.3519 / 0.0344\n",
            "[0/500][209/625] Loss_D: 0.1965 Loss_G: 4.3838 D(x): 0.9401 D(G(z)): 0.1144 / 0.0242\n",
            "[0/500][210/625] Loss_D: 0.4496 Loss_G: 3.7218 D(x): 0.8596 D(G(z)): 0.2158 / 0.0344\n",
            "[0/500][211/625] Loss_D: 0.5942 Loss_G: 1.8162 D(x): 0.6906 D(G(z)): 0.0716 / 0.1848\n",
            "[0/500][212/625] Loss_D: 0.5693 Loss_G: 4.4599 D(x): 0.9705 D(G(z)): 0.3895 / 0.0162\n",
            "[0/500][213/625] Loss_D: 0.3717 Loss_G: 3.5130 D(x): 0.7791 D(G(z)): 0.0661 / 0.0374\n",
            "[0/500][214/625] Loss_D: 0.3117 Loss_G: 3.5744 D(x): 0.9054 D(G(z)): 0.1649 / 0.0467\n",
            "[0/500][215/625] Loss_D: 0.2999 Loss_G: 3.5638 D(x): 0.8857 D(G(z)): 0.1504 / 0.0332\n",
            "[0/500][216/625] Loss_D: 0.2805 Loss_G: 3.9093 D(x): 0.9063 D(G(z)): 0.1481 / 0.0232\n",
            "[0/500][217/625] Loss_D: 0.1300 Loss_G: 4.1592 D(x): 0.9515 D(G(z)): 0.0752 / 0.0207\n",
            "[0/500][218/625] Loss_D: 0.3352 Loss_G: 2.3920 D(x): 0.7908 D(G(z)): 0.0753 / 0.1172\n",
            "[0/500][219/625] Loss_D: 0.3664 Loss_G: 4.2206 D(x): 0.9433 D(G(z)): 0.2484 / 0.0222\n",
            "[0/500][220/625] Loss_D: 0.1031 Loss_G: 4.8747 D(x): 0.9484 D(G(z)): 0.0457 / 0.0131\n",
            "[0/500][221/625] Loss_D: 0.2712 Loss_G: 2.9145 D(x): 0.8224 D(G(z)): 0.0273 / 0.0676\n",
            "[0/500][222/625] Loss_D: 0.3035 Loss_G: 4.8459 D(x): 0.9891 D(G(z)): 0.2298 / 0.0107\n",
            "[0/500][223/625] Loss_D: 0.1107 Loss_G: 5.1237 D(x): 0.9577 D(G(z)): 0.0616 / 0.0099\n",
            "[0/500][224/625] Loss_D: 0.1671 Loss_G: 3.5512 D(x): 0.8652 D(G(z)): 0.0155 / 0.0375\n",
            "[0/500][225/625] Loss_D: 0.2312 Loss_G: 2.7457 D(x): 0.9088 D(G(z)): 0.1069 / 0.0767\n",
            "[0/500][226/625] Loss_D: 0.2421 Loss_G: 5.1192 D(x): 0.9692 D(G(z)): 0.1849 / 0.0070\n",
            "[0/500][227/625] Loss_D: 0.2149 Loss_G: 3.7577 D(x): 0.8383 D(G(z)): 0.0236 / 0.0303\n",
            "[0/500][228/625] Loss_D: 0.1496 Loss_G: 3.6785 D(x): 0.9484 D(G(z)): 0.0868 / 0.0327\n",
            "[0/500][229/625] Loss_D: 0.1435 Loss_G: 3.5451 D(x): 0.9244 D(G(z)): 0.0535 / 0.0362\n",
            "[0/500][230/625] Loss_D: 0.1332 Loss_G: 4.2986 D(x): 0.9652 D(G(z)): 0.0903 / 0.0153\n",
            "[0/500][231/625] Loss_D: 0.1145 Loss_G: 4.2386 D(x): 0.9348 D(G(z)): 0.0441 / 0.0210\n",
            "[0/500][232/625] Loss_D: 0.2246 Loss_G: 1.8877 D(x): 0.8457 D(G(z)): 0.0420 / 0.1767\n",
            "[0/500][233/625] Loss_D: 0.3193 Loss_G: 6.8042 D(x): 0.9966 D(G(z)): 0.2607 / 0.0015\n",
            "[0/500][234/625] Loss_D: 0.1614 Loss_G: 6.0527 D(x): 0.8636 D(G(z)): 0.0031 / 0.0035\n",
            "[0/500][235/625] Loss_D: 0.1172 Loss_G: 3.4862 D(x): 0.9015 D(G(z)): 0.0092 / 0.0434\n",
            "[0/500][236/625] Loss_D: 0.2285 Loss_G: 4.7345 D(x): 0.9935 D(G(z)): 0.1698 / 0.0132\n",
            "[0/500][237/625] Loss_D: 0.1705 Loss_G: 3.6821 D(x): 0.8861 D(G(z)): 0.0422 / 0.0323\n",
            "[0/500][238/625] Loss_D: 0.1362 Loss_G: 3.4188 D(x): 0.9254 D(G(z)): 0.0479 / 0.0623\n",
            "[0/500][239/625] Loss_D: 0.1505 Loss_G: 4.8404 D(x): 0.9952 D(G(z)): 0.1243 / 0.0096\n",
            "[0/500][240/625] Loss_D: 0.1592 Loss_G: 3.5002 D(x): 0.8720 D(G(z)): 0.0160 / 0.0440\n",
            "[0/500][241/625] Loss_D: 0.1889 Loss_G: 4.6409 D(x): 0.9911 D(G(z)): 0.1574 / 0.0124\n",
            "[0/500][242/625] Loss_D: 0.0496 Loss_G: 5.4596 D(x): 0.9727 D(G(z)): 0.0210 / 0.0061\n",
            "[0/500][243/625] Loss_D: 0.0528 Loss_G: 4.4612 D(x): 0.9695 D(G(z)): 0.0213 / 0.0143\n",
            "[0/500][244/625] Loss_D: 0.1542 Loss_G: 2.5466 D(x): 0.8922 D(G(z)): 0.0217 / 0.0963\n",
            "[0/500][245/625] Loss_D: 0.1214 Loss_G: 3.0486 D(x): 0.9574 D(G(z)): 0.0720 / 0.0669\n",
            "[0/500][246/625] Loss_D: 0.4545 Loss_G: 9.3512 D(x): 0.9921 D(G(z)): 0.3451 / 0.0001\n",
            "[0/500][247/625] Loss_D: 2.3458 Loss_G: 0.0965 D(x): 0.1437 D(G(z)): 0.0003 / 0.9128\n",
            "[0/500][248/625] Loss_D: 2.4671 Loss_G: 10.0533 D(x): 0.9997 D(G(z)): 0.8954 / 0.0001\n",
            "[0/500][249/625] Loss_D: 5.5052 Loss_G: 1.0179 D(x): 0.0077 D(G(z)): 0.0006 / 0.4293\n",
            "[0/500][250/625] Loss_D: 1.1959 Loss_G: 3.1765 D(x): 0.9941 D(G(z)): 0.6069 / 0.0659\n",
            "[0/500][251/625] Loss_D: 0.3414 Loss_G: 4.9588 D(x): 0.9610 D(G(z)): 0.2158 / 0.0174\n",
            "[0/500][252/625] Loss_D: 0.6805 Loss_G: 2.8473 D(x): 0.6724 D(G(z)): 0.0316 / 0.0879\n",
            "[0/500][253/625] Loss_D: 0.5240 Loss_G: 2.0322 D(x): 0.8556 D(G(z)): 0.2472 / 0.1788\n",
            "[0/500][254/625] Loss_D: 0.6097 Loss_G: 3.0338 D(x): 0.8496 D(G(z)): 0.3270 / 0.0580\n",
            "[0/500][255/625] Loss_D: 0.6882 Loss_G: 1.8718 D(x): 0.6784 D(G(z)): 0.1571 / 0.2110\n",
            "[0/500][256/625] Loss_D: 0.8650 Loss_G: 4.1229 D(x): 0.8892 D(G(z)): 0.4582 / 0.0222\n",
            "[0/500][257/625] Loss_D: 0.9939 Loss_G: 1.6336 D(x): 0.5011 D(G(z)): 0.0519 / 0.2611\n",
            "[0/500][258/625] Loss_D: 0.7311 Loss_G: 4.6551 D(x): 0.9588 D(G(z)): 0.4498 / 0.0125\n",
            "[0/500][259/625] Loss_D: 0.2666 Loss_G: 4.3258 D(x): 0.8151 D(G(z)): 0.0282 / 0.0157\n",
            "[0/500][260/625] Loss_D: 0.3118 Loss_G: 2.3334 D(x): 0.7963 D(G(z)): 0.0496 / 0.1135\n",
            "[0/500][261/625] Loss_D: 0.3558 Loss_G: 3.1936 D(x): 0.9288 D(G(z)): 0.2325 / 0.0460\n",
            "[0/500][262/625] Loss_D: 0.3210 Loss_G: 4.8128 D(x): 0.9499 D(G(z)): 0.2074 / 0.0091\n",
            "[0/500][263/625] Loss_D: 0.2217 Loss_G: 4.2558 D(x): 0.8248 D(G(z)): 0.0152 / 0.0180\n",
            "[0/500][264/625] Loss_D: 0.3286 Loss_G: 1.9637 D(x): 0.8028 D(G(z)): 0.0681 / 0.1741\n",
            "[0/500][265/625] Loss_D: 0.4539 Loss_G: 4.7278 D(x): 0.9779 D(G(z)): 0.3133 / 0.0110\n",
            "[0/500][266/625] Loss_D: 0.1902 Loss_G: 4.5913 D(x): 0.8721 D(G(z)): 0.0394 / 0.0141\n",
            "[0/500][267/625] Loss_D: 0.1502 Loss_G: 3.4758 D(x): 0.9207 D(G(z)): 0.0589 / 0.0370\n",
            "[0/500][268/625] Loss_D: 0.1405 Loss_G: 3.3705 D(x): 0.9069 D(G(z)): 0.0391 / 0.0469\n",
            "[0/500][269/625] Loss_D: 0.1096 Loss_G: 3.7445 D(x): 0.9844 D(G(z)): 0.0846 / 0.0352\n",
            "[0/500][270/625] Loss_D: 0.1553 Loss_G: 3.8632 D(x): 0.9471 D(G(z)): 0.0926 / 0.0263\n",
            "[0/500][271/625] Loss_D: 0.1597 Loss_G: 4.1067 D(x): 0.9305 D(G(z)): 0.0752 / 0.0236\n",
            "[0/500][272/625] Loss_D: 0.3154 Loss_G: 2.2010 D(x): 0.7624 D(G(z)): 0.0225 / 0.1448\n",
            "[0/500][273/625] Loss_D: 0.2551 Loss_G: 3.8587 D(x): 0.9958 D(G(z)): 0.2160 / 0.0246\n",
            "[0/500][274/625] Loss_D: 0.1649 Loss_G: 5.3120 D(x): 0.9865 D(G(z)): 0.1312 / 0.0063\n",
            "[0/500][275/625] Loss_D: 0.1100 Loss_G: 5.3663 D(x): 0.9139 D(G(z)): 0.0137 / 0.0086\n",
            "[0/500][276/625] Loss_D: 0.2389 Loss_G: 2.7178 D(x): 0.8266 D(G(z)): 0.0173 / 0.1104\n",
            "[0/500][277/625] Loss_D: 0.1489 Loss_G: 2.9297 D(x): 0.9758 D(G(z)): 0.1140 / 0.0660\n",
            "[0/500][278/625] Loss_D: 0.3753 Loss_G: 5.4923 D(x): 0.9883 D(G(z)): 0.2584 / 0.0057\n",
            "[0/500][279/625] Loss_D: 0.4029 Loss_G: 2.4968 D(x): 0.7095 D(G(z)): 0.0204 / 0.1080\n",
            "[0/500][280/625] Loss_D: 0.2586 Loss_G: 3.8912 D(x): 0.9764 D(G(z)): 0.2022 / 0.0243\n",
            "[0/500][281/625] Loss_D: 0.1514 Loss_G: 4.7612 D(x): 0.9651 D(G(z)): 0.1047 / 0.0122\n",
            "[0/500][282/625] Loss_D: 0.1735 Loss_G: 4.0139 D(x): 0.8542 D(G(z)): 0.0098 / 0.0243\n",
            "[0/500][283/625] Loss_D: 0.3930 Loss_G: 5.1355 D(x): 0.9424 D(G(z)): 0.2664 / 0.0068\n",
            "[0/500][284/625] Loss_D: 1.1324 Loss_G: 0.4580 D(x): 0.4325 D(G(z)): 0.0115 / 0.6604\n",
            "[0/500][285/625] Loss_D: 2.0584 Loss_G: 9.0438 D(x): 0.9987 D(G(z)): 0.8405 / 0.0002\n",
            "[0/500][286/625] Loss_D: 0.7222 Loss_G: 7.4110 D(x): 0.5970 D(G(z)): 0.0007 / 0.0023\n",
            "[0/500][287/625] Loss_D: 0.2084 Loss_G: 4.3750 D(x): 0.8412 D(G(z)): 0.0054 / 0.0236\n",
            "[0/500][288/625] Loss_D: 0.1713 Loss_G: 4.0690 D(x): 0.9594 D(G(z)): 0.0891 / 0.0627\n",
            "[0/500][289/625] Loss_D: 0.6269 Loss_G: 5.5529 D(x): 0.9641 D(G(z)): 0.3076 / 0.0087\n",
            "[0/500][290/625] Loss_D: 0.2865 Loss_G: 4.1155 D(x): 0.8070 D(G(z)): 0.0380 / 0.0298\n",
            "[0/500][291/625] Loss_D: 0.1036 Loss_G: 3.5059 D(x): 0.9543 D(G(z)): 0.0540 / 0.0363\n",
            "[0/500][292/625] Loss_D: 0.1796 Loss_G: 4.2698 D(x): 0.9740 D(G(z)): 0.1289 / 0.0247\n",
            "[0/500][293/625] Loss_D: 0.2072 Loss_G: 4.2082 D(x): 0.9256 D(G(z)): 0.1117 / 0.0202\n",
            "[0/500][294/625] Loss_D: 0.4696 Loss_G: 1.6728 D(x): 0.7523 D(G(z)): 0.0607 / 0.2143\n",
            "[0/500][295/625] Loss_D: 0.6714 Loss_G: 7.2729 D(x): 0.9828 D(G(z)): 0.4483 / 0.0010\n",
            "[0/500][296/625] Loss_D: 0.8999 Loss_G: 2.1136 D(x): 0.4458 D(G(z)): 0.0038 / 0.1550\n",
            "[0/500][297/625] Loss_D: 0.3588 Loss_G: 4.2311 D(x): 0.9951 D(G(z)): 0.2729 / 0.0202\n",
            "[0/500][298/625] Loss_D: 0.1090 Loss_G: 5.0269 D(x): 0.9738 D(G(z)): 0.0774 / 0.0086\n",
            "[0/500][299/625] Loss_D: 0.0925 Loss_G: 4.6321 D(x): 0.9391 D(G(z)): 0.0268 / 0.0148\n",
            "[0/500][300/625] Loss_D: 0.0868 Loss_G: 3.7834 D(x): 0.9431 D(G(z)): 0.0257 / 0.0286\n",
            "[0/500][301/625] Loss_D: 0.1042 Loss_G: 4.0416 D(x): 0.9865 D(G(z)): 0.0839 / 0.0241\n",
            "[0/500][302/625] Loss_D: 0.1963 Loss_G: 3.3223 D(x): 0.9020 D(G(z)): 0.0827 / 0.0430\n",
            "[0/500][303/625] Loss_D: 0.1233 Loss_G: 3.4374 D(x): 0.9462 D(G(z)): 0.0626 / 0.0363\n",
            "[0/500][304/625] Loss_D: 0.1817 Loss_G: 2.8095 D(x): 0.8964 D(G(z)): 0.0647 / 0.0752\n",
            "[0/500][305/625] Loss_D: 0.2423 Loss_G: 4.5425 D(x): 0.9741 D(G(z)): 0.1843 / 0.0135\n",
            "[0/500][306/625] Loss_D: 0.4353 Loss_G: 1.9465 D(x): 0.7144 D(G(z)): 0.0260 / 0.1741\n",
            "[0/500][307/625] Loss_D: 0.7175 Loss_G: 7.0796 D(x): 0.9950 D(G(z)): 0.4671 / 0.0010\n",
            "[0/500][308/625] Loss_D: 0.3676 Loss_G: 5.5826 D(x): 0.7206 D(G(z)): 0.0016 / 0.0051\n",
            "[0/500][309/625] Loss_D: 0.0537 Loss_G: 3.9020 D(x): 0.9619 D(G(z)): 0.0138 / 0.0298\n",
            "[0/500][310/625] Loss_D: 0.0452 Loss_G: 3.7259 D(x): 0.9875 D(G(z)): 0.0317 / 0.0292\n",
            "[0/500][311/625] Loss_D: 0.0724 Loss_G: 4.2856 D(x): 0.9890 D(G(z)): 0.0579 / 0.0186\n",
            "[0/500][312/625] Loss_D: 0.0726 Loss_G: 4.1435 D(x): 0.9765 D(G(z)): 0.0467 / 0.0209\n",
            "[0/500][313/625] Loss_D: 0.2147 Loss_G: 2.8882 D(x): 0.8843 D(G(z)): 0.0780 / 0.0656\n",
            "[0/500][314/625] Loss_D: 0.2106 Loss_G: 4.2236 D(x): 0.9556 D(G(z)): 0.1426 / 0.0213\n",
            "[0/500][315/625] Loss_D: 0.0979 Loss_G: 4.6071 D(x): 0.9542 D(G(z)): 0.0480 / 0.0145\n",
            "[0/500][316/625] Loss_D: 0.1448 Loss_G: 3.4894 D(x): 0.8922 D(G(z)): 0.0220 / 0.0417\n",
            "[0/500][317/625] Loss_D: 0.0886 Loss_G: 3.3766 D(x): 0.9719 D(G(z)): 0.0573 / 0.0417\n",
            "[0/500][318/625] Loss_D: 0.1157 Loss_G: 4.2131 D(x): 0.9873 D(G(z)): 0.0959 / 0.0181\n",
            "[0/500][319/625] Loss_D: 0.0766 Loss_G: 4.4208 D(x): 0.9481 D(G(z)): 0.0207 / 0.0146\n",
            "[0/500][320/625] Loss_D: 0.0860 Loss_G: 3.6156 D(x): 0.9497 D(G(z)): 0.0311 / 0.0337\n",
            "[0/500][321/625] Loss_D: 0.0508 Loss_G: 4.0251 D(x): 0.9803 D(G(z)): 0.0300 / 0.0214\n",
            "[0/500][322/625] Loss_D: 0.1714 Loss_G: 2.7037 D(x): 0.8989 D(G(z)): 0.0389 / 0.0744\n",
            "[0/500][323/625] Loss_D: 0.1400 Loss_G: 4.6411 D(x): 0.9886 D(G(z)): 0.1186 / 0.0108\n",
            "[0/500][324/625] Loss_D: 0.1537 Loss_G: 3.1880 D(x): 0.8954 D(G(z)): 0.0322 / 0.0451\n",
            "[0/500][325/625] Loss_D: 0.7052 Loss_G: 0.1114 D(x): 0.6082 D(G(z)): 0.0613 / 0.8981\n",
            "[0/500][326/625] Loss_D: 2.4209 Loss_G: 11.9298 D(x): 0.9994 D(G(z)): 0.8768 / 0.0000\n",
            "[0/500][327/625] Loss_D: 5.9880 Loss_G: 4.9971 D(x): 0.0035 D(G(z)): 0.0000 / 0.0169\n",
            "[0/500][328/625] Loss_D: 0.5679 Loss_G: 0.3674 D(x): 0.6290 D(G(z)): 0.0180 / 0.7306\n",
            "[0/500][329/625] Loss_D: 1.8121 Loss_G: 8.5418 D(x): 0.9969 D(G(z)): 0.7791 / 0.0007\n",
            "[0/500][330/625] Loss_D: 3.3093 Loss_G: 0.3859 D(x): 0.0740 D(G(z)): 0.0062 / 0.7284\n",
            "[0/500][331/625] Loss_D: 2.1336 Loss_G: 3.7649 D(x): 0.9932 D(G(z)): 0.8373 / 0.0374\n",
            "[0/500][332/625] Loss_D: 0.4308 Loss_G: 4.9544 D(x): 0.7834 D(G(z)): 0.0846 / 0.0320\n",
            "[0/500][333/625] Loss_D: 0.9221 Loss_G: 1.6960 D(x): 0.5499 D(G(z)): 0.0410 / 0.2619\n",
            "[0/500][334/625] Loss_D: 0.9613 Loss_G: 2.9421 D(x): 0.9659 D(G(z)): 0.5297 / 0.0817\n",
            "[0/500][335/625] Loss_D: 0.8916 Loss_G: 2.3982 D(x): 0.6110 D(G(z)): 0.2080 / 0.1378\n",
            "[0/500][336/625] Loss_D: 0.5735 Loss_G: 2.0491 D(x): 0.7495 D(G(z)): 0.1947 / 0.1687\n",
            "[0/500][337/625] Loss_D: 0.7628 Loss_G: 2.7538 D(x): 0.8072 D(G(z)): 0.3693 / 0.0810\n",
            "[0/500][338/625] Loss_D: 0.9680 Loss_G: 1.7439 D(x): 0.5570 D(G(z)): 0.2638 / 0.2205\n",
            "[0/500][339/625] Loss_D: 0.4410 Loss_G: 3.4037 D(x): 0.9266 D(G(z)): 0.2869 / 0.0435\n",
            "[0/500][340/625] Loss_D: 0.4104 Loss_G: 2.6545 D(x): 0.7773 D(G(z)): 0.1287 / 0.0847\n",
            "[0/500][341/625] Loss_D: 0.7284 Loss_G: 1.6456 D(x): 0.6727 D(G(z)): 0.1949 / 0.2297\n",
            "[0/500][342/625] Loss_D: 0.5536 Loss_G: 4.3870 D(x): 0.9468 D(G(z)): 0.3805 / 0.0148\n",
            "[0/500][343/625] Loss_D: 0.5277 Loss_G: 2.4334 D(x): 0.6720 D(G(z)): 0.0638 / 0.1245\n",
            "[0/500][344/625] Loss_D: 0.3918 Loss_G: 2.5362 D(x): 0.8518 D(G(z)): 0.1862 / 0.0931\n",
            "[0/500][345/625] Loss_D: 0.4474 Loss_G: 3.7508 D(x): 0.8861 D(G(z)): 0.2602 / 0.0275\n",
            "[0/500][346/625] Loss_D: 0.3309 Loss_G: 3.0387 D(x): 0.8000 D(G(z)): 0.0683 / 0.0636\n",
            "[0/500][347/625] Loss_D: 0.3765 Loss_G: 2.0218 D(x): 0.7926 D(G(z)): 0.1082 / 0.1585\n",
            "[0/500][348/625] Loss_D: 0.7591 Loss_G: 4.7142 D(x): 0.9599 D(G(z)): 0.4615 / 0.0111\n",
            "[0/500][349/625] Loss_D: 0.4551 Loss_G: 3.3934 D(x): 0.6608 D(G(z)): 0.0181 / 0.0398\n",
            "[0/500][350/625] Loss_D: 0.2586 Loss_G: 2.0361 D(x): 0.8321 D(G(z)): 0.0569 / 0.1506\n",
            "[0/500][351/625] Loss_D: 0.5440 Loss_G: 3.6822 D(x): 0.9757 D(G(z)): 0.3742 / 0.0310\n",
            "[0/500][352/625] Loss_D: 0.1973 Loss_G: 3.8804 D(x): 0.8887 D(G(z)): 0.0678 / 0.0263\n",
            "[0/500][353/625] Loss_D: 0.4302 Loss_G: 1.9751 D(x): 0.7332 D(G(z)): 0.0610 / 0.1687\n",
            "[0/500][354/625] Loss_D: 0.4770 Loss_G: 2.8928 D(x): 0.9221 D(G(z)): 0.3061 / 0.0744\n",
            "[0/500][355/625] Loss_D: 0.2531 Loss_G: 3.9060 D(x): 0.9329 D(G(z)): 0.1580 / 0.0257\n",
            "[0/500][356/625] Loss_D: 0.3107 Loss_G: 3.1513 D(x): 0.7850 D(G(z)): 0.0466 / 0.0578\n",
            "[0/500][357/625] Loss_D: 0.2907 Loss_G: 2.1532 D(x): 0.8421 D(G(z)): 0.0856 / 0.1415\n",
            "[0/500][358/625] Loss_D: 0.3879 Loss_G: 3.0017 D(x): 0.9278 D(G(z)): 0.2427 / 0.0679\n",
            "[0/500][359/625] Loss_D: 0.2784 Loss_G: 4.4767 D(x): 0.9662 D(G(z)): 0.2039 / 0.0145\n",
            "[0/500][360/625] Loss_D: 0.4452 Loss_G: 3.0211 D(x): 0.7175 D(G(z)): 0.0249 / 0.0679\n",
            "[0/500][361/625] Loss_D: 0.3617 Loss_G: 2.5322 D(x): 0.8790 D(G(z)): 0.1891 / 0.0944\n",
            "[0/500][362/625] Loss_D: 0.1830 Loss_G: 3.7765 D(x): 0.9630 D(G(z)): 0.1303 / 0.0295\n",
            "[0/500][363/625] Loss_D: 0.3145 Loss_G: 2.6559 D(x): 0.8123 D(G(z)): 0.0653 / 0.0858\n",
            "[0/500][364/625] Loss_D: 0.2580 Loss_G: 2.6316 D(x): 0.9023 D(G(z)): 0.1095 / 0.0893\n",
            "[0/500][365/625] Loss_D: 0.2248 Loss_G: 3.6260 D(x): 0.9507 D(G(z)): 0.1487 / 0.0388\n",
            "[0/500][366/625] Loss_D: 0.2509 Loss_G: 3.7322 D(x): 0.8981 D(G(z)): 0.1187 / 0.0341\n",
            "[0/500][367/625] Loss_D: 0.5543 Loss_G: 1.1345 D(x): 0.6531 D(G(z)): 0.0641 / 0.3774\n",
            "[0/500][368/625] Loss_D: 0.6739 Loss_G: 5.4180 D(x): 0.9954 D(G(z)): 0.4626 / 0.0055\n",
            "[0/500][369/625] Loss_D: 0.4273 Loss_G: 3.1754 D(x): 0.6871 D(G(z)): 0.0138 / 0.0474\n",
            "[0/500][370/625] Loss_D: 0.2581 Loss_G: 2.4985 D(x): 0.9061 D(G(z)): 0.1330 / 0.1008\n",
            "[0/500][371/625] Loss_D: 0.2446 Loss_G: 3.8555 D(x): 0.9554 D(G(z)): 0.1695 / 0.0317\n",
            "[0/500][372/625] Loss_D: 0.0803 Loss_G: 4.5549 D(x): 0.9637 D(G(z)): 0.0417 / 0.0134\n",
            "[0/500][373/625] Loss_D: 0.3972 Loss_G: 1.6808 D(x): 0.7202 D(G(z)): 0.0246 / 0.2161\n",
            "[0/500][374/625] Loss_D: 0.4937 Loss_G: 4.2974 D(x): 0.9714 D(G(z)): 0.3485 / 0.0160\n",
            "[0/500][375/625] Loss_D: 0.1701 Loss_G: 4.1460 D(x): 0.8879 D(G(z)): 0.0465 / 0.0199\n",
            "[0/500][376/625] Loss_D: 0.2848 Loss_G: 2.1164 D(x): 0.7879 D(G(z)): 0.0217 / 0.1398\n",
            "[0/500][377/625] Loss_D: 0.6783 Loss_G: 5.0986 D(x): 0.9402 D(G(z)): 0.4384 / 0.0074\n",
            "[0/500][378/625] Loss_D: 0.4201 Loss_G: 2.5292 D(x): 0.6716 D(G(z)): 0.0126 / 0.0900\n",
            "[0/500][379/625] Loss_D: 0.3168 Loss_G: 2.6786 D(x): 0.9199 D(G(z)): 0.1889 / 0.1002\n",
            "[0/500][380/625] Loss_D: 0.1894 Loss_G: 3.4830 D(x): 0.9281 D(G(z)): 0.0976 / 0.0426\n",
            "[0/500][381/625] Loss_D: 0.5881 Loss_G: 2.6276 D(x): 0.7621 D(G(z)): 0.2271 / 0.0832\n",
            "[0/500][382/625] Loss_D: 0.2293 Loss_G: 4.1410 D(x): 0.9328 D(G(z)): 0.1305 / 0.0256\n",
            "[0/500][383/625] Loss_D: 0.1778 Loss_G: 3.6731 D(x): 0.9101 D(G(z)): 0.0746 / 0.0428\n",
            "[0/500][384/625] Loss_D: 0.3339 Loss_G: 1.8209 D(x): 0.8000 D(G(z)): 0.0890 / 0.2125\n",
            "[0/500][385/625] Loss_D: 0.2369 Loss_G: 4.1302 D(x): 0.9846 D(G(z)): 0.1905 / 0.0203\n",
            "[0/500][386/625] Loss_D: 0.2276 Loss_G: 3.6249 D(x): 0.8815 D(G(z)): 0.0851 / 0.0390\n",
            "[0/500][387/625] Loss_D: 0.0908 Loss_G: 3.8407 D(x): 0.9552 D(G(z)): 0.0430 / 0.0287\n",
            "[0/500][388/625] Loss_D: 0.2097 Loss_G: 2.5280 D(x): 0.8720 D(G(z)): 0.0627 / 0.1005\n",
            "[0/500][389/625] Loss_D: 0.3235 Loss_G: 5.3671 D(x): 0.9750 D(G(z)): 0.2491 / 0.0056\n",
            "[0/500][390/625] Loss_D: 0.4543 Loss_G: 1.4164 D(x): 0.6695 D(G(z)): 0.0163 / 0.2796\n",
            "[0/500][391/625] Loss_D: 0.3550 Loss_G: 4.2494 D(x): 0.9912 D(G(z)): 0.2654 / 0.0216\n",
            "[0/500][392/625] Loss_D: 0.1055 Loss_G: 4.8535 D(x): 0.9552 D(G(z)): 0.0546 / 0.0130\n",
            "[0/500][393/625] Loss_D: 0.2381 Loss_G: 2.6956 D(x): 0.8231 D(G(z)): 0.0185 / 0.0863\n",
            "[0/500][394/625] Loss_D: 0.1729 Loss_G: 3.5263 D(x): 0.9838 D(G(z)): 0.1422 / 0.0341\n",
            "[0/500][395/625] Loss_D: 0.2167 Loss_G: 4.3213 D(x): 0.9311 D(G(z)): 0.1283 / 0.0201\n",
            "[0/500][396/625] Loss_D: 0.3219 Loss_G: 2.4667 D(x): 0.8279 D(G(z)): 0.0871 / 0.1119\n",
            "[0/500][397/625] Loss_D: 0.3325 Loss_G: 3.3853 D(x): 0.8837 D(G(z)): 0.1617 / 0.0391\n",
            "[0/500][398/625] Loss_D: 0.3681 Loss_G: 2.2667 D(x): 0.8072 D(G(z)): 0.1175 / 0.1222\n",
            "[0/500][399/625] Loss_D: 0.1765 Loss_G: 4.5407 D(x): 0.9734 D(G(z)): 0.1336 / 0.0156\n",
            "[0/500][400/625] Loss_D: 0.3815 Loss_G: 1.2906 D(x): 0.7816 D(G(z)): 0.0713 / 0.3146\n",
            "[0/500][401/625] Loss_D: 0.5121 Loss_G: 7.2919 D(x): 0.9722 D(G(z)): 0.3601 / 0.0012\n",
            "[0/500][402/625] Loss_D: 1.0670 Loss_G: 0.0842 D(x): 0.4165 D(G(z)): 0.0019 / 0.9208\n",
            "[0/500][403/625] Loss_D: 3.0276 Loss_G: 10.1761 D(x): 0.9993 D(G(z)): 0.9174 / 0.0001\n",
            "[0/500][404/625] Loss_D: 3.8221 Loss_G: 3.5988 D(x): 0.0611 D(G(z)): 0.0001 / 0.0501\n",
            "[0/500][405/625] Loss_D: 0.1582 Loss_G: 3.1691 D(x): 0.9787 D(G(z)): 0.1170 / 0.0772\n",
            "[0/500][406/625] Loss_D: 0.6920 Loss_G: 4.6730 D(x): 0.8628 D(G(z)): 0.3406 / 0.0169\n",
            "[0/500][407/625] Loss_D: 1.0488 Loss_G: 0.1245 D(x): 0.4745 D(G(z)): 0.0594 / 0.8861\n",
            "[0/500][408/625] Loss_D: 2.0118 Loss_G: 6.1829 D(x): 0.9932 D(G(z)): 0.8365 / 0.0030\n",
            "[0/500][409/625] Loss_D: 0.5509 Loss_G: 4.8494 D(x): 0.6325 D(G(z)): 0.0207 / 0.0214\n",
            "[0/500][410/625] Loss_D: 0.5827 Loss_G: 1.6547 D(x): 0.7183 D(G(z)): 0.0602 / 0.2701\n",
            "[0/500][411/625] Loss_D: 0.5179 Loss_G: 2.9010 D(x): 0.9685 D(G(z)): 0.3334 / 0.0855\n",
            "[0/500][412/625] Loss_D: 0.2464 Loss_G: 3.4955 D(x): 0.9030 D(G(z)): 0.1215 / 0.0391\n",
            "[0/500][413/625] Loss_D: 0.8304 Loss_G: 1.5003 D(x): 0.6464 D(G(z)): 0.1147 / 0.2669\n",
            "[0/500][414/625] Loss_D: 1.4849 Loss_G: 5.8570 D(x): 0.9720 D(G(z)): 0.7095 / 0.0057\n",
            "[0/500][415/625] Loss_D: 1.5997 Loss_G: 1.7917 D(x): 0.3405 D(G(z)): 0.0223 / 0.2460\n",
            "[0/500][416/625] Loss_D: 0.3823 Loss_G: 1.6467 D(x): 0.8651 D(G(z)): 0.1897 / 0.2434\n",
            "[0/500][417/625] Loss_D: 0.9640 Loss_G: 5.4364 D(x): 0.9544 D(G(z)): 0.5200 / 0.0070\n",
            "[0/500][418/625] Loss_D: 0.4447 Loss_G: 4.4180 D(x): 0.7157 D(G(z)): 0.0251 / 0.0219\n",
            "[0/500][419/625] Loss_D: 0.8092 Loss_G: 0.8656 D(x): 0.5396 D(G(z)): 0.0366 / 0.4704\n",
            "[0/500][420/625] Loss_D: 1.5987 Loss_G: 5.3119 D(x): 0.9979 D(G(z)): 0.7073 / 0.0077\n",
            "[0/500][421/625] Loss_D: 0.8828 Loss_G: 3.1578 D(x): 0.5417 D(G(z)): 0.0187 / 0.0684\n",
            "[0/500][422/625] Loss_D: 0.2253 Loss_G: 2.4934 D(x): 0.9266 D(G(z)): 0.1261 / 0.1062\n",
            "[0/500][423/625] Loss_D: 0.2467 Loss_G: 3.4825 D(x): 0.9606 D(G(z)): 0.1806 / 0.0372\n",
            "[0/500][424/625] Loss_D: 0.3818 Loss_G: 2.6334 D(x): 0.7857 D(G(z)): 0.0877 / 0.0869\n",
            "[0/500][425/625] Loss_D: 0.3245 Loss_G: 3.5010 D(x): 0.9505 D(G(z)): 0.1942 / 0.0538\n",
            "[0/500][426/625] Loss_D: 0.2507 Loss_G: 3.9727 D(x): 0.9225 D(G(z)): 0.1452 / 0.0242\n",
            "[0/500][427/625] Loss_D: 0.3968 Loss_G: 2.5920 D(x): 0.7413 D(G(z)): 0.0406 / 0.0933\n",
            "[0/500][428/625] Loss_D: 0.3142 Loss_G: 3.0394 D(x): 0.9179 D(G(z)): 0.1948 / 0.0572\n",
            "[0/500][429/625] Loss_D: 0.4045 Loss_G: 1.9935 D(x): 0.7752 D(G(z)): 0.1303 / 0.1585\n",
            "[0/500][430/625] Loss_D: 0.4938 Loss_G: 4.2228 D(x): 0.9267 D(G(z)): 0.3233 / 0.0189\n",
            "[0/500][431/625] Loss_D: 0.4114 Loss_G: 2.7998 D(x): 0.7654 D(G(z)): 0.0513 / 0.0745\n",
            "[0/500][432/625] Loss_D: 0.2432 Loss_G: 3.1863 D(x): 0.9086 D(G(z)): 0.1258 / 0.0579\n",
            "[0/500][433/625] Loss_D: 0.2521 Loss_G: 2.9608 D(x): 0.8816 D(G(z)): 0.1066 / 0.0661\n",
            "[0/500][434/625] Loss_D: 0.1725 Loss_G: 3.2023 D(x): 0.9332 D(G(z)): 0.0900 / 0.0478\n",
            "[0/500][435/625] Loss_D: 0.3863 Loss_G: 4.1762 D(x): 0.9084 D(G(z)): 0.2363 / 0.0186\n",
            "[0/500][436/625] Loss_D: 0.4070 Loss_G: 2.1221 D(x): 0.7087 D(G(z)): 0.0282 / 0.1374\n",
            "[0/500][437/625] Loss_D: 0.4820 Loss_G: 4.9637 D(x): 0.9488 D(G(z)): 0.3273 / 0.0101\n",
            "[0/500][438/625] Loss_D: 1.0231 Loss_G: 1.0293 D(x): 0.4521 D(G(z)): 0.0225 / 0.4131\n",
            "[0/500][439/625] Loss_D: 0.7608 Loss_G: 9.0987 D(x): 0.9050 D(G(z)): 0.4438 / 0.0002\n",
            "[0/500][440/625] Loss_D: 5.3047 Loss_G: 0.0100 D(x): 0.0168 D(G(z)): 0.0009 / 0.9900\n",
            "[0/500][441/625] Loss_D: 4.1246 Loss_G: 7.7018 D(x): 0.9999 D(G(z)): 0.9788 / 0.0010\n",
            "[0/500][442/625] Loss_D: 2.1109 Loss_G: 1.9494 D(x): 0.1590 D(G(z)): 0.0021 / 0.2376\n",
            "[0/500][443/625] Loss_D: 0.6179 Loss_G: 2.7256 D(x): 0.9955 D(G(z)): 0.3972 / 0.1272\n",
            "[0/500][444/625] Loss_D: 0.5601 Loss_G: 4.4185 D(x): 0.9660 D(G(z)): 0.3701 / 0.0168\n",
            "[0/500][445/625] Loss_D: 0.5911 Loss_G: 2.9446 D(x): 0.6102 D(G(z)): 0.0247 / 0.0658\n",
            "[0/500][446/625] Loss_D: 0.3151 Loss_G: 2.6919 D(x): 0.9596 D(G(z)): 0.2221 / 0.0881\n",
            "[0/500][447/625] Loss_D: 0.3538 Loss_G: 2.8220 D(x): 0.8367 D(G(z)): 0.1469 / 0.0814\n",
            "[0/500][448/625] Loss_D: 0.4588 Loss_G: 2.1256 D(x): 0.7883 D(G(z)): 0.1626 / 0.1402\n",
            "[0/500][449/625] Loss_D: 0.5668 Loss_G: 2.5640 D(x): 0.8366 D(G(z)): 0.2868 / 0.0997\n",
            "[0/500][450/625] Loss_D: 0.5778 Loss_G: 2.0461 D(x): 0.7205 D(G(z)): 0.1829 / 0.1784\n",
            "[0/500][451/625] Loss_D: 0.6588 Loss_G: 3.5402 D(x): 0.8797 D(G(z)): 0.3872 / 0.0343\n",
            "[0/500][452/625] Loss_D: 0.7935 Loss_G: 1.3026 D(x): 0.5392 D(G(z)): 0.0711 / 0.3185\n",
            "[0/500][453/625] Loss_D: 0.7936 Loss_G: 3.2420 D(x): 0.9010 D(G(z)): 0.4661 / 0.0567\n",
            "[0/500][454/625] Loss_D: 0.4750 Loss_G: 2.9019 D(x): 0.7219 D(G(z)): 0.1119 / 0.0946\n",
            "[0/500][455/625] Loss_D: 0.2946 Loss_G: 2.5416 D(x): 0.8685 D(G(z)): 0.1283 / 0.1047\n",
            "[0/500][456/625] Loss_D: 0.4308 Loss_G: 3.1734 D(x): 0.9037 D(G(z)): 0.2443 / 0.0672\n",
            "[0/500][457/625] Loss_D: 0.3062 Loss_G: 3.0018 D(x): 0.8487 D(G(z)): 0.1177 / 0.0661\n",
            "[0/500][458/625] Loss_D: 0.3565 Loss_G: 2.5889 D(x): 0.8406 D(G(z)): 0.1441 / 0.1074\n",
            "[0/500][459/625] Loss_D: 0.3585 Loss_G: 2.5560 D(x): 0.8624 D(G(z)): 0.1792 / 0.0941\n",
            "[0/500][460/625] Loss_D: 0.5059 Loss_G: 1.9712 D(x): 0.7650 D(G(z)): 0.1518 / 0.1598\n",
            "[0/500][461/625] Loss_D: 0.3955 Loss_G: 3.0568 D(x): 0.8937 D(G(z)): 0.2241 / 0.0601\n",
            "[0/500][462/625] Loss_D: 0.4130 Loss_G: 2.5439 D(x): 0.7943 D(G(z)): 0.1347 / 0.0976\n",
            "[0/500][463/625] Loss_D: 0.2755 Loss_G: 2.9120 D(x): 0.9094 D(G(z)): 0.1505 / 0.0683\n",
            "[0/500][464/625] Loss_D: 0.5080 Loss_G: 2.6812 D(x): 0.8024 D(G(z)): 0.2203 / 0.0832\n",
            "[0/500][465/625] Loss_D: 0.5180 Loss_G: 1.4747 D(x): 0.7045 D(G(z)): 0.1230 / 0.2482\n",
            "[0/500][466/625] Loss_D: 0.3752 Loss_G: 3.4112 D(x): 0.9307 D(G(z)): 0.2456 / 0.0408\n",
            "[0/500][467/625] Loss_D: 0.7959 Loss_G: 0.9450 D(x): 0.5759 D(G(z)): 0.1052 / 0.4332\n",
            "[0/500][468/625] Loss_D: 0.5654 Loss_G: 4.2021 D(x): 0.9781 D(G(z)): 0.3805 / 0.0202\n",
            "[0/500][469/625] Loss_D: 0.4043 Loss_G: 2.9711 D(x): 0.7304 D(G(z)): 0.0449 / 0.0740\n",
            "[0/500][470/625] Loss_D: 0.3411 Loss_G: 3.2723 D(x): 0.9246 D(G(z)): 0.2069 / 0.0510\n",
            "[0/500][471/625] Loss_D: 0.4746 Loss_G: 1.5240 D(x): 0.7016 D(G(z)): 0.0585 / 0.2496\n",
            "[0/500][472/625] Loss_D: 0.6943 Loss_G: 4.4080 D(x): 0.9504 D(G(z)): 0.4208 / 0.0184\n",
            "[0/500][473/625] Loss_D: 0.2839 Loss_G: 3.5286 D(x): 0.7952 D(G(z)): 0.0338 / 0.0381\n",
            "[0/500][474/625] Loss_D: 0.4629 Loss_G: 1.1417 D(x): 0.7330 D(G(z)): 0.0874 / 0.3519\n",
            "[0/500][475/625] Loss_D: 0.9584 Loss_G: 4.5647 D(x): 0.9397 D(G(z)): 0.5526 / 0.0130\n",
            "[0/500][476/625] Loss_D: 0.3265 Loss_G: 4.1402 D(x): 0.7584 D(G(z)): 0.0163 / 0.0214\n",
            "[0/500][477/625] Loss_D: 0.7180 Loss_G: 0.6897 D(x): 0.5663 D(G(z)): 0.0283 / 0.5172\n",
            "[0/500][478/625] Loss_D: 1.7411 Loss_G: 4.2052 D(x): 0.9940 D(G(z)): 0.7722 / 0.0206\n",
            "[0/500][479/625] Loss_D: 0.6037 Loss_G: 3.2460 D(x): 0.6338 D(G(z)): 0.0462 / 0.0492\n",
            "[0/500][480/625] Loss_D: 0.2810 Loss_G: 2.3820 D(x): 0.8154 D(G(z)): 0.0602 / 0.1423\n",
            "[0/500][481/625] Loss_D: 0.2920 Loss_G: 2.9463 D(x): 0.9388 D(G(z)): 0.1879 / 0.0842\n",
            "[0/500][482/625] Loss_D: 0.3489 Loss_G: 3.2089 D(x): 0.8891 D(G(z)): 0.1747 / 0.0589\n",
            "[0/500][483/625] Loss_D: 0.4194 Loss_G: 1.6697 D(x): 0.7656 D(G(z)): 0.0951 / 0.2320\n",
            "[0/500][484/625] Loss_D: 0.2736 Loss_G: 2.9306 D(x): 0.9428 D(G(z)): 0.1869 / 0.0593\n",
            "[0/500][485/625] Loss_D: 0.2532 Loss_G: 3.8481 D(x): 0.9213 D(G(z)): 0.1458 / 0.0329\n",
            "[0/500][486/625] Loss_D: 0.4960 Loss_G: 1.4977 D(x): 0.6770 D(G(z)): 0.0617 / 0.2622\n",
            "[0/500][487/625] Loss_D: 0.5239 Loss_G: 2.7656 D(x): 0.9268 D(G(z)): 0.3228 / 0.0794\n",
            "[0/500][488/625] Loss_D: 0.2568 Loss_G: 3.0161 D(x): 0.8622 D(G(z)): 0.0943 / 0.0549\n",
            "[0/500][489/625] Loss_D: 0.2173 Loss_G: 2.9215 D(x): 0.8858 D(G(z)): 0.0845 / 0.0766\n",
            "[0/500][490/625] Loss_D: 0.1337 Loss_G: 3.5633 D(x): 0.9749 D(G(z)): 0.0997 / 0.0395\n",
            "[0/500][491/625] Loss_D: 0.2546 Loss_G: 2.5293 D(x): 0.8406 D(G(z)): 0.0625 / 0.0951\n",
            "[0/500][492/625] Loss_D: 0.3143 Loss_G: 3.8021 D(x): 0.9694 D(G(z)): 0.2355 / 0.0270\n",
            "[0/500][493/625] Loss_D: 0.4033 Loss_G: 2.0446 D(x): 0.7134 D(G(z)): 0.0358 / 0.1606\n",
            "[0/500][494/625] Loss_D: 0.2805 Loss_G: 2.1296 D(x): 0.9106 D(G(z)): 0.1598 / 0.1275\n",
            "[0/500][495/625] Loss_D: 0.3597 Loss_G: 3.5841 D(x): 0.9172 D(G(z)): 0.2258 / 0.0336\n",
            "[0/500][496/625] Loss_D: 0.3822 Loss_G: 2.5479 D(x): 0.7955 D(G(z)): 0.0721 / 0.1039\n",
            "[0/500][497/625] Loss_D: 0.2384 Loss_G: 3.1159 D(x): 0.9279 D(G(z)): 0.1424 / 0.0613\n",
            "[0/500][498/625] Loss_D: 0.1805 Loss_G: 3.0151 D(x): 0.8951 D(G(z)): 0.0597 / 0.0607\n",
            "[0/500][499/625] Loss_D: 0.2303 Loss_G: 2.3273 D(x): 0.9003 D(G(z)): 0.1045 / 0.1100\n",
            "[0/500][500/625] Loss_D: 0.1827 Loss_G: 3.1488 D(x): 0.9463 D(G(z)): 0.1171 / 0.0479\n",
            "[0/500][501/625] Loss_D: 0.1478 Loss_G: 3.7215 D(x): 0.9574 D(G(z)): 0.0969 / 0.0275\n",
            "[0/500][502/625] Loss_D: 0.7423 Loss_G: 0.3975 D(x): 0.5352 D(G(z)): 0.0456 / 0.6831\n",
            "[0/500][503/625] Loss_D: 1.2937 Loss_G: 7.5837 D(x): 0.9926 D(G(z)): 0.6947 / 0.0008\n",
            "[0/500][504/625] Loss_D: 2.5863 Loss_G: 2.2141 D(x): 0.1355 D(G(z)): 0.0017 / 0.1259\n",
            "[0/500][505/625] Loss_D: 0.4209 Loss_G: 3.5375 D(x): 0.9001 D(G(z)): 0.2434 / 0.0375\n",
            "[0/500][506/625] Loss_D: 1.3186 Loss_G: 0.0173 D(x): 0.3317 D(G(z)): 0.1140 / 0.9829\n",
            "[0/500][507/625] Loss_D: 4.6663 Loss_G: 3.4472 D(x): 0.9968 D(G(z)): 0.9879 / 0.0413\n",
            "[0/500][508/625] Loss_D: 1.2238 Loss_G: 1.8800 D(x): 0.4116 D(G(z)): 0.1141 / 0.2107\n",
            "[0/500][509/625] Loss_D: 0.9095 Loss_G: 2.2309 D(x): 0.7811 D(G(z)): 0.4211 / 0.1327\n",
            "[0/500][510/625] Loss_D: 0.9258 Loss_G: 2.3289 D(x): 0.6864 D(G(z)): 0.2910 / 0.1305\n",
            "[0/500][511/625] Loss_D: 0.9996 Loss_G: 1.7676 D(x): 0.6596 D(G(z)): 0.2953 / 0.2444\n",
            "[0/500][512/625] Loss_D: 0.8151 Loss_G: 2.8270 D(x): 0.8204 D(G(z)): 0.3709 / 0.1031\n",
            "[0/500][513/625] Loss_D: 0.7805 Loss_G: 3.1282 D(x): 0.7295 D(G(z)): 0.3288 / 0.0612\n",
            "[0/500][514/625] Loss_D: 0.3506 Loss_G: 2.7253 D(x): 0.7866 D(G(z)): 0.0873 / 0.0957\n",
            "[0/500][515/625] Loss_D: 0.8061 Loss_G: 0.9712 D(x): 0.6139 D(G(z)): 0.2086 / 0.4129\n",
            "[0/500][516/625] Loss_D: 1.0469 Loss_G: 4.2098 D(x): 0.9298 D(G(z)): 0.5682 / 0.0200\n",
            "[0/500][517/625] Loss_D: 0.9911 Loss_G: 0.9726 D(x): 0.4234 D(G(z)): 0.0423 / 0.4117\n",
            "[0/500][518/625] Loss_D: 0.7523 Loss_G: 3.0177 D(x): 0.9319 D(G(z)): 0.4518 / 0.0624\n",
            "[0/500][519/625] Loss_D: 0.5406 Loss_G: 2.0827 D(x): 0.6763 D(G(z)): 0.1102 / 0.1592\n",
            "[0/500][520/625] Loss_D: 0.3113 Loss_G: 2.4889 D(x): 0.8810 D(G(z)): 0.1576 / 0.1095\n",
            "[0/500][521/625] Loss_D: 0.5256 Loss_G: 2.6549 D(x): 0.8513 D(G(z)): 0.2558 / 0.0957\n",
            "[0/500][522/625] Loss_D: 0.3787 Loss_G: 2.2227 D(x): 0.7733 D(G(z)): 0.0960 / 0.1369\n",
            "[0/500][523/625] Loss_D: 0.4054 Loss_G: 3.5864 D(x): 0.9581 D(G(z)): 0.2794 / 0.0395\n",
            "[0/500][524/625] Loss_D: 0.5718 Loss_G: 1.4304 D(x): 0.6450 D(G(z)): 0.0707 / 0.2663\n",
            "[0/500][525/625] Loss_D: 0.5323 Loss_G: 2.9764 D(x): 0.9357 D(G(z)): 0.3426 / 0.0651\n",
            "[0/500][526/625] Loss_D: 0.4617 Loss_G: 3.2023 D(x): 0.8320 D(G(z)): 0.2131 / 0.0517\n",
            "[0/500][527/625] Loss_D: 0.6395 Loss_G: 0.8876 D(x): 0.5773 D(G(z)): 0.0475 / 0.4534\n",
            "[0/500][528/625] Loss_D: 0.8131 Loss_G: 2.8884 D(x): 0.9010 D(G(z)): 0.4738 / 0.0656\n",
            "[0/500][529/625] Loss_D: 0.5737 Loss_G: 2.1671 D(x): 0.6986 D(G(z)): 0.1630 / 0.1295\n",
            "[0/500][530/625] Loss_D: 0.3722 Loss_G: 3.0440 D(x): 0.8992 D(G(z)): 0.2122 / 0.0647\n",
            "[0/500][531/625] Loss_D: 0.3628 Loss_G: 2.3568 D(x): 0.8145 D(G(z)): 0.1239 / 0.1096\n",
            "[0/500][532/625] Loss_D: 0.3285 Loss_G: 1.9995 D(x): 0.8278 D(G(z)): 0.1204 / 0.1494\n",
            "[0/500][533/625] Loss_D: 0.4427 Loss_G: 3.2179 D(x): 0.9098 D(G(z)): 0.2796 / 0.0463\n",
            "[0/500][534/625] Loss_D: 0.3431 Loss_G: 2.1676 D(x): 0.7726 D(G(z)): 0.0732 / 0.1275\n",
            "[0/500][535/625] Loss_D: 0.3592 Loss_G: 2.0400 D(x): 0.8311 D(G(z)): 0.1409 / 0.1676\n",
            "[0/500][536/625] Loss_D: 0.5087 Loss_G: 3.3696 D(x): 0.8740 D(G(z)): 0.2975 / 0.0402\n",
            "[0/500][537/625] Loss_D: 0.5245 Loss_G: 1.1052 D(x): 0.6695 D(G(z)): 0.0847 / 0.3502\n",
            "[0/500][538/625] Loss_D: 0.5881 Loss_G: 4.0508 D(x): 0.9465 D(G(z)): 0.3669 / 0.0218\n",
            "[0/500][539/625] Loss_D: 0.7425 Loss_G: 0.6414 D(x): 0.5367 D(G(z)): 0.0349 / 0.5625\n",
            "[0/500][540/625] Loss_D: 0.6684 Loss_G: 3.8617 D(x): 0.9729 D(G(z)): 0.4410 / 0.0326\n",
            "[0/500][541/625] Loss_D: 0.4275 Loss_G: 2.6332 D(x): 0.7617 D(G(z)): 0.1108 / 0.0930\n",
            "[0/500][542/625] Loss_D: 0.2786 Loss_G: 2.5015 D(x): 0.8697 D(G(z)): 0.1181 / 0.1046\n",
            "[0/500][543/625] Loss_D: 0.3383 Loss_G: 2.6656 D(x): 0.8739 D(G(z)): 0.1703 / 0.0852\n",
            "[0/500][544/625] Loss_D: 0.3408 Loss_G: 2.4142 D(x): 0.8296 D(G(z)): 0.1243 / 0.1097\n",
            "[0/500][545/625] Loss_D: 0.3220 Loss_G: 2.3850 D(x): 0.8632 D(G(z)): 0.1536 / 0.1038\n",
            "[0/500][546/625] Loss_D: 0.2431 Loss_G: 2.6536 D(x): 0.8922 D(G(z)): 0.1140 / 0.0839\n",
            "[0/500][547/625] Loss_D: 0.3869 Loss_G: 1.9734 D(x): 0.8118 D(G(z)): 0.1512 / 0.1513\n",
            "[0/500][548/625] Loss_D: 0.3714 Loss_G: 2.7504 D(x): 0.8725 D(G(z)): 0.1972 / 0.0672\n",
            "[0/500][549/625] Loss_D: 0.3041 Loss_G: 2.3389 D(x): 0.8386 D(G(z)): 0.1071 / 0.1104\n",
            "[0/500][550/625] Loss_D: 0.3973 Loss_G: 2.4188 D(x): 0.8481 D(G(z)): 0.1887 / 0.0977\n",
            "[0/500][551/625] Loss_D: 0.2307 Loss_G: 2.8006 D(x): 0.9000 D(G(z)): 0.1104 / 0.0758\n",
            "[0/500][552/625] Loss_D: 0.2833 Loss_G: 2.3903 D(x): 0.8537 D(G(z)): 0.1078 / 0.1181\n",
            "[0/500][553/625] Loss_D: 0.3319 Loss_G: 2.4400 D(x): 0.8731 D(G(z)): 0.1607 / 0.1053\n",
            "[0/500][554/625] Loss_D: 0.2983 Loss_G: 3.3660 D(x): 0.9074 D(G(z)): 0.1750 / 0.0410\n",
            "[0/500][555/625] Loss_D: 0.3948 Loss_G: 1.2923 D(x): 0.7532 D(G(z)): 0.0740 / 0.3249\n",
            "[0/500][556/625] Loss_D: 0.5857 Loss_G: 5.1809 D(x): 0.9585 D(G(z)): 0.3847 / 0.0063\n",
            "[0/500][557/625] Loss_D: 0.6737 Loss_G: 1.0824 D(x): 0.5725 D(G(z)): 0.0197 / 0.3597\n",
            "[0/500][558/625] Loss_D: 0.4887 Loss_G: 3.3991 D(x): 0.9564 D(G(z)): 0.3232 / 0.0429\n",
            "[0/500][559/625] Loss_D: 0.2139 Loss_G: 3.6078 D(x): 0.9041 D(G(z)): 0.1000 / 0.0332\n",
            "[0/500][560/625] Loss_D: 0.3504 Loss_G: 1.6429 D(x): 0.7765 D(G(z)): 0.0676 / 0.2310\n",
            "[0/500][561/625] Loss_D: 0.5419 Loss_G: 4.0231 D(x): 0.9233 D(G(z)): 0.3463 / 0.0217\n",
            "[0/500][562/625] Loss_D: 0.4530 Loss_G: 1.8304 D(x): 0.7036 D(G(z)): 0.0311 / 0.1917\n",
            "[0/500][563/625] Loss_D: 0.1803 Loss_G: 2.3430 D(x): 0.9525 D(G(z)): 0.1185 / 0.1115\n",
            "[0/500][564/625] Loss_D: 0.3404 Loss_G: 3.7372 D(x): 0.9343 D(G(z)): 0.2251 / 0.0285\n",
            "[0/500][565/625] Loss_D: 0.7989 Loss_G: 0.4850 D(x): 0.5867 D(G(z)): 0.1066 / 0.6360\n",
            "[0/500][566/625] Loss_D: 0.8028 Loss_G: 4.8886 D(x): 0.9529 D(G(z)): 0.4768 / 0.0108\n",
            "[0/500][567/625] Loss_D: 0.4791 Loss_G: 2.1308 D(x): 0.6887 D(G(z)): 0.0280 / 0.1659\n",
            "[0/500][568/625] Loss_D: 0.4779 Loss_G: 3.0776 D(x): 0.9075 D(G(z)): 0.3002 / 0.0544\n",
            "[0/500][569/625] Loss_D: 0.3276 Loss_G: 2.4574 D(x): 0.8080 D(G(z)): 0.0834 / 0.1106\n",
            "[0/500][570/625] Loss_D: 0.2015 Loss_G: 2.4345 D(x): 0.8943 D(G(z)): 0.0762 / 0.1133\n",
            "[0/500][571/625] Loss_D: 0.2958 Loss_G: 3.7950 D(x): 0.9506 D(G(z)): 0.2101 / 0.0243\n",
            "[0/500][572/625] Loss_D: 0.6837 Loss_G: 0.4711 D(x): 0.5593 D(G(z)): 0.0338 / 0.6346\n",
            "[0/500][573/625] Loss_D: 1.0602 Loss_G: 7.0405 D(x): 0.9814 D(G(z)): 0.6059 / 0.0011\n",
            "[0/500][574/625] Loss_D: 1.5248 Loss_G: 1.3454 D(x): 0.3701 D(G(z)): 0.0026 / 0.3112\n",
            "[0/500][575/625] Loss_D: 0.7772 Loss_G: 4.8190 D(x): 0.9815 D(G(z)): 0.5028 / 0.0100\n",
            "[0/500][576/625] Loss_D: 0.6840 Loss_G: 0.8042 D(x): 0.5923 D(G(z)): 0.0352 / 0.4666\n",
            "[0/500][577/625] Loss_D: 0.4753 Loss_G: 3.4016 D(x): 0.9754 D(G(z)): 0.3257 / 0.0448\n",
            "[0/500][578/625] Loss_D: 0.1638 Loss_G: 4.2419 D(x): 0.9312 D(G(z)): 0.0734 / 0.0220\n",
            "[0/500][579/625] Loss_D: 0.2932 Loss_G: 2.6558 D(x): 0.8280 D(G(z)): 0.0782 / 0.1034\n",
            "[0/500][580/625] Loss_D: 0.2912 Loss_G: 2.2722 D(x): 0.8608 D(G(z)): 0.1175 / 0.1378\n",
            "[0/500][581/625] Loss_D: 0.3878 Loss_G: 3.2981 D(x): 0.9069 D(G(z)): 0.2298 / 0.0464\n",
            "[0/500][582/625] Loss_D: 0.3955 Loss_G: 1.9168 D(x): 0.7395 D(G(z)): 0.0551 / 0.1883\n",
            "[0/500][583/625] Loss_D: 0.4497 Loss_G: 3.4729 D(x): 0.9410 D(G(z)): 0.2889 / 0.0432\n",
            "[0/500][584/625] Loss_D: 0.4832 Loss_G: 1.5456 D(x): 0.7424 D(G(z)): 0.0916 / 0.2431\n",
            "[0/500][585/625] Loss_D: 0.4319 Loss_G: 3.3745 D(x): 0.9123 D(G(z)): 0.2608 / 0.0442\n",
            "[0/500][586/625] Loss_D: 0.1657 Loss_G: 3.6438 D(x): 0.9152 D(G(z)): 0.0691 / 0.0349\n",
            "[0/500][587/625] Loss_D: 0.1929 Loss_G: 2.6404 D(x): 0.8744 D(G(z)): 0.0478 / 0.0820\n",
            "[0/500][588/625] Loss_D: 0.2279 Loss_G: 3.0179 D(x): 0.9301 D(G(z)): 0.1342 / 0.0615\n",
            "[0/500][589/625] Loss_D: 0.3763 Loss_G: 1.8015 D(x): 0.7764 D(G(z)): 0.0874 / 0.2128\n",
            "[0/500][590/625] Loss_D: 0.6553 Loss_G: 6.0820 D(x): 0.9616 D(G(z)): 0.3968 / 0.0039\n",
            "[0/500][591/625] Loss_D: 1.2682 Loss_G: 0.2191 D(x): 0.3461 D(G(z)): 0.0167 / 0.8215\n",
            "[0/500][592/625] Loss_D: 1.5009 Loss_G: 7.3135 D(x): 0.9805 D(G(z)): 0.7332 / 0.0009\n",
            "[0/500][593/625] Loss_D: 2.7785 Loss_G: 0.8308 D(x): 0.0938 D(G(z)): 0.0022 / 0.4947\n",
            "[0/500][594/625] Loss_D: 1.4157 Loss_G: 5.6126 D(x): 0.9873 D(G(z)): 0.6864 / 0.0084\n",
            "[0/500][595/625] Loss_D: 1.7924 Loss_G: 0.8614 D(x): 0.2953 D(G(z)): 0.0154 / 0.4662\n",
            "[0/500][596/625] Loss_D: 1.3528 Loss_G: 3.6480 D(x): 0.9719 D(G(z)): 0.6234 / 0.0475\n",
            "[0/500][597/625] Loss_D: 0.7019 Loss_G: 2.1390 D(x): 0.6031 D(G(z)): 0.0925 / 0.1912\n",
            "[0/500][598/625] Loss_D: 0.3920 Loss_G: 2.1891 D(x): 0.8959 D(G(z)): 0.2297 / 0.1291\n",
            "[0/500][599/625] Loss_D: 0.6369 Loss_G: 3.4997 D(x): 0.8747 D(G(z)): 0.3466 / 0.0425\n",
            "[0/500][600/625] Loss_D: 0.7562 Loss_G: 1.4233 D(x): 0.5943 D(G(z)): 0.0603 / 0.2913\n",
            "[0/500][601/625] Loss_D: 0.7576 Loss_G: 1.5971 D(x): 0.7935 D(G(z)): 0.3663 / 0.2323\n",
            "[0/500][602/625] Loss_D: 0.8006 Loss_G: 3.5040 D(x): 0.8292 D(G(z)): 0.3895 / 0.0392\n",
            "[0/500][603/625] Loss_D: 0.5610 Loss_G: 1.9357 D(x): 0.6760 D(G(z)): 0.0933 / 0.1910\n",
            "[0/500][604/625] Loss_D: 0.3608 Loss_G: 2.3547 D(x): 0.8949 D(G(z)): 0.1997 / 0.1211\n",
            "[0/500][605/625] Loss_D: 0.5126 Loss_G: 2.9740 D(x): 0.8472 D(G(z)): 0.2513 / 0.0784\n",
            "[0/500][606/625] Loss_D: 0.4317 Loss_G: 2.9432 D(x): 0.8358 D(G(z)): 0.1832 / 0.0729\n",
            "[0/500][607/625] Loss_D: 0.5694 Loss_G: 1.2181 D(x): 0.6485 D(G(z)): 0.0847 / 0.3429\n",
            "[0/500][608/625] Loss_D: 0.8054 Loss_G: 3.8764 D(x): 0.8973 D(G(z)): 0.4654 / 0.0249\n",
            "[0/500][609/625] Loss_D: 0.5484 Loss_G: 2.0941 D(x): 0.6433 D(G(z)): 0.0333 / 0.1892\n",
            "[0/500][610/625] Loss_D: 0.2938 Loss_G: 2.5177 D(x): 0.9521 D(G(z)): 0.2059 / 0.1021\n",
            "[0/500][611/625] Loss_D: 0.4195 Loss_G: 3.7304 D(x): 0.9190 D(G(z)): 0.2559 / 0.0362\n",
            "[0/500][612/625] Loss_D: 0.7890 Loss_G: 1.1092 D(x): 0.5466 D(G(z)): 0.0583 / 0.3784\n",
            "[0/500][613/625] Loss_D: 0.8699 Loss_G: 3.9051 D(x): 0.9807 D(G(z)): 0.5229 / 0.0245\n",
            "[0/500][614/625] Loss_D: 0.6303 Loss_G: 2.3103 D(x): 0.6184 D(G(z)): 0.0512 / 0.1197\n",
            "[0/500][615/625] Loss_D: 0.4346 Loss_G: 3.0795 D(x): 0.9213 D(G(z)): 0.2745 / 0.0665\n",
            "[0/500][616/625] Loss_D: 0.3290 Loss_G: 2.6237 D(x): 0.8088 D(G(z)): 0.0808 / 0.0924\n",
            "[0/500][617/625] Loss_D: 0.4720 Loss_G: 2.3141 D(x): 0.8353 D(G(z)): 0.2357 / 0.1052\n",
            "[0/500][618/625] Loss_D: 0.3184 Loss_G: 2.2716 D(x): 0.8140 D(G(z)): 0.0907 / 0.1354\n",
            "[0/500][619/625] Loss_D: 0.2436 Loss_G: 2.6309 D(x): 0.9259 D(G(z)): 0.1455 / 0.0846\n",
            "[0/500][620/625] Loss_D: 0.5094 Loss_G: 3.4697 D(x): 0.8951 D(G(z)): 0.2909 / 0.0419\n",
            "[0/500][621/625] Loss_D: 0.8498 Loss_G: 0.7683 D(x): 0.5284 D(G(z)): 0.0612 / 0.5115\n",
            "[0/500][622/625] Loss_D: 0.8164 Loss_G: 1.9904 D(x): 0.8060 D(G(z)): 0.4031 / 0.1581\n",
            "[0/500][623/625] Loss_D: 0.6190 Loss_G: 2.9579 D(x): 0.8069 D(G(z)): 0.2836 / 0.0724\n",
            "[0/500][624/625] Loss_D: 0.4391 Loss_G: 2.6012 D(x): 0.8012 D(G(z)): 0.1787 / 0.0827\n",
            "[1/500][0/625] Loss_D: 0.3323 Loss_G: 2.7295 D(x): 0.8525 D(G(z)): 0.1407 / 0.0822\n",
            "[1/500][1/625] Loss_D: 0.2518 Loss_G: 2.5088 D(x): 0.8701 D(G(z)): 0.0966 / 0.0896\n",
            "[1/500][2/625] Loss_D: 0.8088 Loss_G: 0.5646 D(x): 0.5570 D(G(z)): 0.1405 / 0.5955\n",
            "[1/500][3/625] Loss_D: 1.2922 Loss_G: 5.6959 D(x): 0.9845 D(G(z)): 0.6977 / 0.0041\n",
            "[1/500][4/625] Loss_D: 1.2250 Loss_G: 1.5488 D(x): 0.3562 D(G(z)): 0.0188 / 0.2608\n",
            "[1/500][5/625] Loss_D: 0.2930 Loss_G: 2.3064 D(x): 0.9519 D(G(z)): 0.2030 / 0.1272\n",
            "[1/500][6/625] Loss_D: 0.3706 Loss_G: 3.0189 D(x): 0.8802 D(G(z)): 0.2016 / 0.0623\n",
            "[1/500][7/625] Loss_D: 0.4591 Loss_G: 1.4624 D(x): 0.7340 D(G(z)): 0.0869 / 0.2466\n",
            "[1/500][8/625] Loss_D: 0.6975 Loss_G: 4.3241 D(x): 0.9507 D(G(z)): 0.4412 / 0.0173\n",
            "[1/500][9/625] Loss_D: 0.8259 Loss_G: 1.1947 D(x): 0.5029 D(G(z)): 0.0307 / 0.3288\n",
            "[1/500][10/625] Loss_D: 0.4272 Loss_G: 2.6929 D(x): 0.9618 D(G(z)): 0.3007 / 0.0777\n",
            "[1/500][11/625] Loss_D: 0.3173 Loss_G: 3.5227 D(x): 0.8905 D(G(z)): 0.1694 / 0.0379\n",
            "[1/500][12/625] Loss_D: 0.4126 Loss_G: 2.6634 D(x): 0.7983 D(G(z)): 0.1300 / 0.1082\n",
            "[1/500][13/625] Loss_D: 0.3836 Loss_G: 1.8823 D(x): 0.7992 D(G(z)): 0.1232 / 0.1832\n",
            "[1/500][14/625] Loss_D: 0.5716 Loss_G: 3.5718 D(x): 0.8770 D(G(z)): 0.3298 / 0.0370\n",
            "[1/500][15/625] Loss_D: 0.3295 Loss_G: 2.7832 D(x): 0.7858 D(G(z)): 0.0579 / 0.0774\n",
            "[1/500][16/625] Loss_D: 0.3407 Loss_G: 1.9865 D(x): 0.8331 D(G(z)): 0.1350 / 0.1898\n",
            "[1/500][17/625] Loss_D: 0.4080 Loss_G: 2.8100 D(x): 0.8933 D(G(z)): 0.2369 / 0.0682\n",
            "[1/500][18/625] Loss_D: 0.3406 Loss_G: 2.3146 D(x): 0.8051 D(G(z)): 0.1080 / 0.1295\n",
            "[1/500][19/625] Loss_D: 0.3805 Loss_G: 2.8253 D(x): 0.8874 D(G(z)): 0.2167 / 0.0671\n",
            "[1/500][20/625] Loss_D: 0.2898 Loss_G: 2.2788 D(x): 0.8177 D(G(z)): 0.0725 / 0.1206\n",
            "[1/500][21/625] Loss_D: 0.2804 Loss_G: 3.0689 D(x): 0.9191 D(G(z)): 0.1647 / 0.0704\n",
            "[1/500][22/625] Loss_D: 0.3895 Loss_G: 2.2421 D(x): 0.8118 D(G(z)): 0.1367 / 0.1197\n",
            "[1/500][23/625] Loss_D: 0.2840 Loss_G: 2.3626 D(x): 0.8757 D(G(z)): 0.1329 / 0.1051\n",
            "[1/500][24/625] Loss_D: 0.4150 Loss_G: 1.8772 D(x): 0.7858 D(G(z)): 0.1404 / 0.1827\n",
            "[1/500][25/625] Loss_D: 0.3750 Loss_G: 3.9480 D(x): 0.9490 D(G(z)): 0.2611 / 0.0241\n",
            "[1/500][26/625] Loss_D: 1.1046 Loss_G: 0.2395 D(x): 0.4089 D(G(z)): 0.0479 / 0.7946\n",
            "[1/500][27/625] Loss_D: 1.9507 Loss_G: 9.4402 D(x): 0.9914 D(G(z)): 0.8191 / 0.0001\n",
            "[1/500][28/625] Loss_D: 5.8738 Loss_G: 2.5058 D(x): 0.0050 D(G(z)): 0.0005 / 0.1302\n",
            "[1/500][29/625] Loss_D: 0.7797 Loss_G: 2.7713 D(x): 0.7121 D(G(z)): 0.2798 / 0.1124\n",
            "[1/500][30/625] Loss_D: 1.0953 Loss_G: 0.2228 D(x): 0.5255 D(G(z)): 0.1263 / 0.8245\n",
            "[1/500][31/625] Loss_D: 3.4967 Loss_G: 6.8336 D(x): 0.9961 D(G(z)): 0.9626 / 0.0018\n",
            "[1/500][32/625] Loss_D: 3.8348 Loss_G: 0.6498 D(x): 0.0473 D(G(z)): 0.0048 / 0.5867\n",
            "[1/500][33/625] Loss_D: 1.3757 Loss_G: 2.2857 D(x): 0.9390 D(G(z)): 0.6330 / 0.1467\n",
            "[1/500][34/625] Loss_D: 0.8959 Loss_G: 2.9229 D(x): 0.7150 D(G(z)): 0.2944 / 0.0804\n",
            "[1/500][35/625] Loss_D: 1.4168 Loss_G: 0.7630 D(x): 0.3735 D(G(z)): 0.1784 / 0.5078\n",
            "[1/500][36/625] Loss_D: 0.9615 Loss_G: 2.4054 D(x): 0.9294 D(G(z)): 0.5151 / 0.1239\n",
            "[1/500][37/625] Loss_D: 0.7661 Loss_G: 2.6540 D(x): 0.7549 D(G(z)): 0.3363 / 0.0899\n",
            "[1/500][38/625] Loss_D: 1.0023 Loss_G: 1.2599 D(x): 0.5186 D(G(z)): 0.1354 / 0.3266\n",
            "[1/500][39/625] Loss_D: 1.0684 Loss_G: 2.1534 D(x): 0.7858 D(G(z)): 0.5252 / 0.1416\n",
            "[1/500][40/625] Loss_D: 0.9989 Loss_G: 1.6940 D(x): 0.5561 D(G(z)): 0.1705 / 0.2556\n",
            "[1/500][41/625] Loss_D: 0.8148 Loss_G: 2.4322 D(x): 0.8319 D(G(z)): 0.3654 / 0.1370\n",
            "[1/500][42/625] Loss_D: 0.6533 Loss_G: 3.0946 D(x): 0.8061 D(G(z)): 0.3230 / 0.0608\n",
            "[1/500][43/625] Loss_D: 0.5566 Loss_G: 2.3916 D(x): 0.6778 D(G(z)): 0.0635 / 0.1186\n",
            "[1/500][44/625] Loss_D: 0.4652 Loss_G: 2.1513 D(x): 0.8407 D(G(z)): 0.2109 / 0.1679\n",
            "[1/500][45/625] Loss_D: 0.5555 Loss_G: 1.8397 D(x): 0.7613 D(G(z)): 0.2065 / 0.1930\n",
            "[1/500][46/625] Loss_D: 0.7274 Loss_G: 3.1960 D(x): 0.8760 D(G(z)): 0.3963 / 0.0522\n",
            "[1/500][47/625] Loss_D: 0.7737 Loss_G: 1.5827 D(x): 0.5576 D(G(z)): 0.1182 / 0.2498\n",
            "[1/500][48/625] Loss_D: 0.6849 Loss_G: 1.7457 D(x): 0.8122 D(G(z)): 0.3212 / 0.1914\n",
            "[1/500][49/625] Loss_D: 0.5771 Loss_G: 2.5798 D(x): 0.8169 D(G(z)): 0.2820 / 0.0870\n",
            "[1/500][50/625] Loss_D: 0.6988 Loss_G: 1.3895 D(x): 0.6250 D(G(z)): 0.1511 / 0.2922\n",
            "[1/500][51/625] Loss_D: 0.7622 Loss_G: 1.4239 D(x): 0.7333 D(G(z)): 0.3117 / 0.2717\n",
            "[1/500][52/625] Loss_D: 0.5592 Loss_G: 2.2249 D(x): 0.8150 D(G(z)): 0.2549 / 0.1265\n",
            "[1/500][53/625] Loss_D: 0.6211 Loss_G: 2.0262 D(x): 0.7522 D(G(z)): 0.2560 / 0.1509\n",
            "[1/500][54/625] Loss_D: 0.5988 Loss_G: 3.2006 D(x): 0.8578 D(G(z)): 0.3208 / 0.0526\n",
            "[1/500][55/625] Loss_D: 0.6619 Loss_G: 1.2717 D(x): 0.6091 D(G(z)): 0.0934 / 0.2944\n",
            "[1/500][56/625] Loss_D: 0.6191 Loss_G: 2.8929 D(x): 0.8981 D(G(z)): 0.3761 / 0.0676\n",
            "[1/500][57/625] Loss_D: 0.7579 Loss_G: 1.2319 D(x): 0.5732 D(G(z)): 0.1032 / 0.3493\n",
            "[1/500][58/625] Loss_D: 0.5984 Loss_G: 2.4403 D(x): 0.9215 D(G(z)): 0.3699 / 0.1083\n",
            "[1/500][59/625] Loss_D: 0.5139 Loss_G: 3.0250 D(x): 0.8399 D(G(z)): 0.2613 / 0.0631\n",
            "[1/500][60/625] Loss_D: 0.5937 Loss_G: 1.4946 D(x): 0.6344 D(G(z)): 0.0846 / 0.2551\n",
            "[1/500][61/625] Loss_D: 0.4254 Loss_G: 1.9815 D(x): 0.8582 D(G(z)): 0.2113 / 0.1639\n",
            "[1/500][62/625] Loss_D: 0.5987 Loss_G: 2.0148 D(x): 0.7808 D(G(z)): 0.2768 / 0.1470\n",
            "[1/500][63/625] Loss_D: 0.5233 Loss_G: 2.9229 D(x): 0.8709 D(G(z)): 0.2835 / 0.0671\n",
            "[1/500][64/625] Loss_D: 0.3969 Loss_G: 2.6435 D(x): 0.7961 D(G(z)): 0.1337 / 0.0887\n",
            "[1/500][65/625] Loss_D: 0.7671 Loss_G: 0.9828 D(x): 0.5955 D(G(z)): 0.1865 / 0.4055\n",
            "[1/500][66/625] Loss_D: 0.4396 Loss_G: 2.4925 D(x): 0.9290 D(G(z)): 0.2954 / 0.0939\n",
            "[1/500][67/625] Loss_D: 0.4206 Loss_G: 2.7267 D(x): 0.8120 D(G(z)): 0.1684 / 0.0854\n",
            "[1/500][68/625] Loss_D: 0.6498 Loss_G: 1.1908 D(x): 0.6711 D(G(z)): 0.1027 / 0.3215\n",
            "[1/500][69/625] Loss_D: 0.3634 Loss_G: 2.2655 D(x): 0.9316 D(G(z)): 0.2443 / 0.1172\n",
            "[1/500][70/625] Loss_D: 0.3988 Loss_G: 3.1073 D(x): 0.9110 D(G(z)): 0.2460 / 0.0515\n",
            "[1/500][71/625] Loss_D: 0.5250 Loss_G: 1.8844 D(x): 0.6957 D(G(z)): 0.1203 / 0.1770\n",
            "[1/500][72/625] Loss_D: 0.4155 Loss_G: 2.7368 D(x): 0.8837 D(G(z)): 0.2397 / 0.0744\n",
            "[1/500][73/625] Loss_D: 0.3804 Loss_G: 2.0346 D(x): 0.7867 D(G(z)): 0.0912 / 0.1453\n",
            "[1/500][74/625] Loss_D: 0.3996 Loss_G: 1.7872 D(x): 0.8123 D(G(z)): 0.1624 / 0.1769\n",
            "[1/500][75/625] Loss_D: 0.4640 Loss_G: 2.6458 D(x): 0.8660 D(G(z)): 0.2597 / 0.0821\n",
            "[1/500][76/625] Loss_D: 0.5896 Loss_G: 1.5100 D(x): 0.6769 D(G(z)): 0.1367 / 0.2563\n",
            "[1/500][77/625] Loss_D: 0.5902 Loss_G: 3.1473 D(x): 0.9087 D(G(z)): 0.3686 / 0.0490\n",
            "[1/500][78/625] Loss_D: 0.8258 Loss_G: 0.9880 D(x): 0.5553 D(G(z)): 0.0766 / 0.4156\n",
            "[1/500][79/625] Loss_D: 0.8680 Loss_G: 3.1902 D(x): 0.8953 D(G(z)): 0.5001 / 0.0496\n",
            "[1/500][80/625] Loss_D: 0.7101 Loss_G: 1.8203 D(x): 0.5970 D(G(z)): 0.0669 / 0.2070\n",
            "[1/500][81/625] Loss_D: 0.6325 Loss_G: 2.4854 D(x): 0.8737 D(G(z)): 0.3649 / 0.0960\n",
            "[1/500][82/625] Loss_D: 0.4705 Loss_G: 2.3000 D(x): 0.7805 D(G(z)): 0.1467 / 0.1182\n",
            "[1/500][83/625] Loss_D: 0.2795 Loss_G: 2.7079 D(x): 0.9104 D(G(z)): 0.1628 / 0.0741\n",
            "[1/500][84/625] Loss_D: 0.3647 Loss_G: 2.3233 D(x): 0.8260 D(G(z)): 0.1424 / 0.1061\n",
            "[1/500][85/625] Loss_D: 0.4326 Loss_G: 2.5746 D(x): 0.8643 D(G(z)): 0.2267 / 0.0901\n",
            "[1/500][86/625] Loss_D: 0.4278 Loss_G: 1.6573 D(x): 0.7327 D(G(z)): 0.0930 / 0.2183\n",
            "[1/500][87/625] Loss_D: 0.5530 Loss_G: 1.6793 D(x): 0.7898 D(G(z)): 0.2333 / 0.2159\n",
            "[1/500][88/625] Loss_D: 0.4128 Loss_G: 3.1329 D(x): 0.9106 D(G(z)): 0.2643 / 0.0470\n",
            "[1/500][89/625] Loss_D: 0.3885 Loss_G: 2.5806 D(x): 0.7826 D(G(z)): 0.0952 / 0.0919\n",
            "[1/500][90/625] Loss_D: 0.4449 Loss_G: 1.6054 D(x): 0.7630 D(G(z)): 0.1384 / 0.2193\n",
            "[1/500][91/625] Loss_D: 0.7532 Loss_G: 2.6627 D(x): 0.7927 D(G(z)): 0.3671 / 0.0844\n",
            "[1/500][92/625] Loss_D: 0.5081 Loss_G: 2.9143 D(x): 0.7945 D(G(z)): 0.2171 / 0.0749\n",
            "[1/500][93/625] Loss_D: 0.6016 Loss_G: 0.8342 D(x): 0.6396 D(G(z)): 0.0958 / 0.4694\n",
            "[1/500][94/625] Loss_D: 0.5992 Loss_G: 3.7619 D(x): 0.9725 D(G(z)): 0.4108 / 0.0288\n",
            "[1/500][95/625] Loss_D: 0.5230 Loss_G: 2.1243 D(x): 0.6811 D(G(z)): 0.0435 / 0.1354\n",
            "[1/500][96/625] Loss_D: 0.5069 Loss_G: 2.7446 D(x): 0.8868 D(G(z)): 0.2722 / 0.0926\n",
            "[1/500][97/625] Loss_D: 0.6214 Loss_G: 1.1301 D(x): 0.6544 D(G(z)): 0.1235 / 0.3518\n",
            "[1/500][98/625] Loss_D: 0.6035 Loss_G: 3.8687 D(x): 0.9282 D(G(z)): 0.3900 / 0.0255\n",
            "[1/500][99/625] Loss_D: 0.7910 Loss_G: 0.8815 D(x): 0.5420 D(G(z)): 0.0699 / 0.4639\n",
            "[1/500][100/625] Loss_D: 0.7655 Loss_G: 3.6238 D(x): 0.9279 D(G(z)): 0.4487 / 0.0327\n",
            "[1/500][101/625] Loss_D: 0.5713 Loss_G: 2.4386 D(x): 0.7072 D(G(z)): 0.1525 / 0.1153\n",
            "[1/500][102/625] Loss_D: 0.3782 Loss_G: 1.9522 D(x): 0.7953 D(G(z)): 0.1192 / 0.1760\n",
            "[1/500][103/625] Loss_D: 0.4820 Loss_G: 2.6316 D(x): 0.8653 D(G(z)): 0.2370 / 0.1014\n",
            "[1/500][104/625] Loss_D: 0.3312 Loss_G: 2.4399 D(x): 0.8265 D(G(z)): 0.1141 / 0.1017\n",
            "[1/500][105/625] Loss_D: 0.4008 Loss_G: 2.6428 D(x): 0.8558 D(G(z)): 0.1999 / 0.0844\n",
            "[1/500][106/625] Loss_D: 0.5456 Loss_G: 2.0934 D(x): 0.7676 D(G(z)): 0.2037 / 0.1511\n",
            "[1/500][107/625] Loss_D: 0.5488 Loss_G: 3.7549 D(x): 0.8737 D(G(z)): 0.3045 / 0.0301\n",
            "[1/500][108/625] Loss_D: 1.0016 Loss_G: 0.4710 D(x): 0.4598 D(G(z)): 0.0644 / 0.6478\n",
            "[1/500][109/625] Loss_D: 1.6870 Loss_G: 6.0838 D(x): 0.9926 D(G(z)): 0.7643 / 0.0029\n",
            "[1/500][110/625] Loss_D: 2.1809 Loss_G: 1.2568 D(x): 0.2078 D(G(z)): 0.0043 / 0.3522\n",
            "[1/500][111/625] Loss_D: 0.8782 Loss_G: 2.7805 D(x): 0.9309 D(G(z)): 0.4647 / 0.1055\n",
            "[1/500][112/625] Loss_D: 0.7471 Loss_G: 3.3069 D(x): 0.7705 D(G(z)): 0.3056 / 0.0452\n",
            "[1/500][113/625] Loss_D: 0.5914 Loss_G: 1.5525 D(x): 0.6718 D(G(z)): 0.0897 / 0.2956\n",
            "[1/500][114/625] Loss_D: 0.6929 Loss_G: 3.1133 D(x): 0.9294 D(G(z)): 0.3943 / 0.0659\n",
            "[1/500][115/625] Loss_D: 0.5992 Loss_G: 2.1641 D(x): 0.6319 D(G(z)): 0.0634 / 0.1649\n",
            "[1/500][116/625] Loss_D: 0.3614 Loss_G: 2.3127 D(x): 0.8922 D(G(z)): 0.1981 / 0.1291\n",
            "[1/500][117/625] Loss_D: 0.6590 Loss_G: 4.2432 D(x): 0.9041 D(G(z)): 0.3771 / 0.0187\n",
            "[1/500][118/625] Loss_D: 1.0232 Loss_G: 1.1695 D(x): 0.4247 D(G(z)): 0.0653 / 0.4049\n",
            "[1/500][119/625] Loss_D: 0.8149 Loss_G: 3.4340 D(x): 0.9673 D(G(z)): 0.4872 / 0.0442\n",
            "[1/500][120/625] Loss_D: 0.4948 Loss_G: 2.8635 D(x): 0.7428 D(G(z)): 0.0657 / 0.0640\n",
            "[1/500][121/625] Loss_D: 0.4335 Loss_G: 2.0120 D(x): 0.8171 D(G(z)): 0.1899 / 0.1546\n",
            "[1/500][122/625] Loss_D: 0.5653 Loss_G: 2.0851 D(x): 0.7989 D(G(z)): 0.2393 / 0.1404\n",
            "[1/500][123/625] Loss_D: 0.5260 Loss_G: 2.5530 D(x): 0.8067 D(G(z)): 0.2336 / 0.0973\n",
            "[1/500][124/625] Loss_D: 0.7283 Loss_G: 1.4138 D(x): 0.6510 D(G(z)): 0.1962 / 0.2827\n",
            "[1/500][125/625] Loss_D: 0.4124 Loss_G: 3.2382 D(x): 0.9525 D(G(z)): 0.2941 / 0.0463\n",
            "[1/500][126/625] Loss_D: 0.9363 Loss_G: 0.8896 D(x): 0.5211 D(G(z)): 0.1418 / 0.4335\n",
            "[1/500][127/625] Loss_D: 1.2572 Loss_G: 4.1699 D(x): 0.9096 D(G(z)): 0.6125 / 0.0192\n",
            "[1/500][128/625] Loss_D: 0.8418 Loss_G: 1.8431 D(x): 0.4953 D(G(z)): 0.0523 / 0.2322\n",
            "[1/500][129/625] Loss_D: 0.6694 Loss_G: 1.8541 D(x): 0.7564 D(G(z)): 0.2844 / 0.1785\n",
            "[1/500][130/625] Loss_D: 0.4363 Loss_G: 3.6971 D(x): 0.9175 D(G(z)): 0.2589 / 0.0338\n",
            "[1/500][131/625] Loss_D: 1.0863 Loss_G: 0.3050 D(x): 0.4306 D(G(z)): 0.0366 / 0.7543\n",
            "[1/500][132/625] Loss_D: 1.9467 Loss_G: 4.1107 D(x): 0.9959 D(G(z)): 0.7959 / 0.0295\n",
            "[1/500][133/625] Loss_D: 0.4542 Loss_G: 3.7844 D(x): 0.7039 D(G(z)): 0.0558 / 0.0417\n",
            "[1/500][134/625] Loss_D: 1.0862 Loss_G: 0.6054 D(x): 0.4510 D(G(z)): 0.0944 / 0.5933\n",
            "[1/500][135/625] Loss_D: 1.0982 Loss_G: 3.0264 D(x): 0.9425 D(G(z)): 0.6189 / 0.0560\n",
            "[1/500][136/625] Loss_D: 0.5577 Loss_G: 2.6282 D(x): 0.7232 D(G(z)): 0.1396 / 0.0918\n",
            "[1/500][137/625] Loss_D: 1.0133 Loss_G: 0.6802 D(x): 0.4805 D(G(z)): 0.1504 / 0.5474\n",
            "[1/500][138/625] Loss_D: 1.0019 Loss_G: 2.8334 D(x): 0.9835 D(G(z)): 0.5455 / 0.0917\n",
            "[1/500][139/625] Loss_D: 0.5010 Loss_G: 3.2129 D(x): 0.8158 D(G(z)): 0.2292 / 0.0477\n",
            "[1/500][140/625] Loss_D: 0.4459 Loss_G: 2.4400 D(x): 0.6889 D(G(z)): 0.0457 / 0.1114\n",
            "[1/500][141/625] Loss_D: 0.7645 Loss_G: 0.9467 D(x): 0.6416 D(G(z)): 0.2390 / 0.4261\n",
            "[1/500][142/625] Loss_D: 0.6235 Loss_G: 3.3708 D(x): 0.9682 D(G(z)): 0.4070 / 0.0379\n",
            "[1/500][143/625] Loss_D: 0.6178 Loss_G: 2.0063 D(x): 0.6517 D(G(z)): 0.0969 / 0.1698\n",
            "[1/500][144/625] Loss_D: 0.4379 Loss_G: 1.7804 D(x): 0.8157 D(G(z)): 0.1823 / 0.2000\n",
            "[1/500][145/625] Loss_D: 0.5512 Loss_G: 3.1562 D(x): 0.9027 D(G(z)): 0.3362 / 0.0506\n",
            "[1/500][146/625] Loss_D: 0.5425 Loss_G: 1.9344 D(x): 0.6540 D(G(z)): 0.0750 / 0.1814\n",
            "[1/500][147/625] Loss_D: 0.4045 Loss_G: 1.7842 D(x): 0.8385 D(G(z)): 0.1787 / 0.1864\n",
            "[1/500][148/625] Loss_D: 0.7353 Loss_G: 3.7988 D(x): 0.9418 D(G(z)): 0.4598 / 0.0258\n",
            "[1/500][149/625] Loss_D: 1.1124 Loss_G: 1.1569 D(x): 0.3907 D(G(z)): 0.0723 / 0.3887\n",
            "[1/500][150/625] Loss_D: 0.4753 Loss_G: 2.1434 D(x): 0.9262 D(G(z)): 0.3065 / 0.1437\n",
            "[1/500][151/625] Loss_D: 0.4655 Loss_G: 2.3730 D(x): 0.7796 D(G(z)): 0.1771 / 0.1021\n",
            "[1/500][152/625] Loss_D: 0.5290 Loss_G: 3.1479 D(x): 0.8728 D(G(z)): 0.2989 / 0.0538\n",
            "[1/500][153/625] Loss_D: 0.5509 Loss_G: 1.6934 D(x): 0.6597 D(G(z)): 0.0852 / 0.2266\n",
            "[1/500][154/625] Loss_D: 0.4366 Loss_G: 2.0464 D(x): 0.8663 D(G(z)): 0.2372 / 0.1444\n",
            "[1/500][155/625] Loss_D: 0.4476 Loss_G: 3.3463 D(x): 0.8915 D(G(z)): 0.2576 / 0.0433\n",
            "[1/500][156/625] Loss_D: 0.5609 Loss_G: 1.4749 D(x): 0.6360 D(G(z)): 0.0766 / 0.2632\n",
            "[1/500][157/625] Loss_D: 0.6804 Loss_G: 2.7965 D(x): 0.8523 D(G(z)): 0.3772 / 0.0729\n",
            "[1/500][158/625] Loss_D: 0.3050 Loss_G: 2.8408 D(x): 0.8296 D(G(z)): 0.0980 / 0.0755\n",
            "[1/500][159/625] Loss_D: 0.3523 Loss_G: 2.4331 D(x): 0.8301 D(G(z)): 0.1120 / 0.1195\n",
            "[1/500][160/625] Loss_D: 0.4018 Loss_G: 2.3033 D(x): 0.8540 D(G(z)): 0.2017 / 0.1147\n",
            "[1/500][161/625] Loss_D: 0.4985 Loss_G: 1.9844 D(x): 0.7676 D(G(z)): 0.1780 / 0.1700\n",
            "[1/500][162/625] Loss_D: 0.4426 Loss_G: 2.8614 D(x): 0.8767 D(G(z)): 0.2531 / 0.0615\n",
            "[1/500][163/625] Loss_D: 0.4762 Loss_G: 1.9793 D(x): 0.7492 D(G(z)): 0.1312 / 0.1586\n",
            "[1/500][164/625] Loss_D: 0.4672 Loss_G: 2.5176 D(x): 0.8429 D(G(z)): 0.2369 / 0.0959\n",
            "[1/500][165/625] Loss_D: 0.4147 Loss_G: 1.7072 D(x): 0.7149 D(G(z)): 0.0561 / 0.2065\n",
            "[1/500][166/625] Loss_D: 0.9358 Loss_G: 5.0749 D(x): 0.9013 D(G(z)): 0.5266 / 0.0077\n",
            "[1/500][167/625] Loss_D: 1.7900 Loss_G: 1.0672 D(x): 0.2308 D(G(z)): 0.0166 / 0.4003\n",
            "[1/500][168/625] Loss_D: 0.8570 Loss_G: 6.7349 D(x): 0.9480 D(G(z)): 0.4865 / 0.0015\n",
            "[1/500][169/625] Loss_D: 3.3904 Loss_G: 0.0659 D(x): 0.0435 D(G(z)): 0.0051 / 0.9389\n",
            "[1/500][170/625] Loss_D: 3.8269 Loss_G: 3.1277 D(x): 0.9987 D(G(z)): 0.9615 / 0.1217\n",
            "[1/500][171/625] Loss_D: 0.9642 Loss_G: 2.7600 D(x): 0.5667 D(G(z)): 0.1636 / 0.0945\n",
            "[1/500][172/625] Loss_D: 0.9772 Loss_G: 1.2455 D(x): 0.5206 D(G(z)): 0.1711 / 0.3702\n",
            "[1/500][173/625] Loss_D: 1.1145 Loss_G: 1.9063 D(x): 0.7930 D(G(z)): 0.4994 / 0.1875\n",
            "[1/500][174/625] Loss_D: 0.8406 Loss_G: 1.9794 D(x): 0.6797 D(G(z)): 0.2416 / 0.1662\n",
            "[1/500][175/625] Loss_D: 1.1615 Loss_G: 1.5485 D(x): 0.6015 D(G(z)): 0.3696 / 0.2700\n",
            "[1/500][176/625] Loss_D: 0.8363 Loss_G: 2.1629 D(x): 0.7221 D(G(z)): 0.3361 / 0.1516\n",
            "[1/500][177/625] Loss_D: 0.8147 Loss_G: 1.9452 D(x): 0.6695 D(G(z)): 0.2683 / 0.2195\n",
            "[1/500][178/625] Loss_D: 1.0256 Loss_G: 0.8702 D(x): 0.5554 D(G(z)): 0.2178 / 0.4401\n",
            "[1/500][179/625] Loss_D: 1.1172 Loss_G: 2.5071 D(x): 0.8870 D(G(z)): 0.5804 / 0.1070\n",
            "[1/500][180/625] Loss_D: 1.0039 Loss_G: 0.9943 D(x): 0.4885 D(G(z)): 0.1095 / 0.4241\n",
            "[1/500][181/625] Loss_D: 1.1310 Loss_G: 2.3519 D(x): 0.8661 D(G(z)): 0.5685 / 0.1300\n",
            "[1/500][182/625] Loss_D: 0.8657 Loss_G: 1.9774 D(x): 0.6303 D(G(z)): 0.2316 / 0.1774\n",
            "[1/500][183/625] Loss_D: 0.7466 Loss_G: 1.4953 D(x): 0.6941 D(G(z)): 0.2103 / 0.2587\n",
            "[1/500][184/625] Loss_D: 0.9817 Loss_G: 1.2991 D(x): 0.6445 D(G(z)): 0.3525 / 0.2890\n",
            "[1/500][185/625] Loss_D: 0.5769 Loss_G: 2.4582 D(x): 0.8451 D(G(z)): 0.2932 / 0.1164\n",
            "[1/500][186/625] Loss_D: 1.0295 Loss_G: 1.2362 D(x): 0.5226 D(G(z)): 0.2254 / 0.3368\n",
            "[1/500][187/625] Loss_D: 0.8859 Loss_G: 2.4220 D(x): 0.8420 D(G(z)): 0.4662 / 0.0975\n",
            "[1/500][188/625] Loss_D: 0.5611 Loss_G: 2.4175 D(x): 0.7449 D(G(z)): 0.1900 / 0.1217\n",
            "[1/500][189/625] Loss_D: 0.7814 Loss_G: 1.3102 D(x): 0.6268 D(G(z)): 0.1936 / 0.2937\n",
            "[1/500][190/625] Loss_D: 0.7585 Loss_G: 2.0483 D(x): 0.8083 D(G(z)): 0.3846 / 0.1515\n",
            "[1/500][191/625] Loss_D: 0.5312 Loss_G: 2.6314 D(x): 0.8175 D(G(z)): 0.2365 / 0.0826\n",
            "[1/500][192/625] Loss_D: 0.5548 Loss_G: 2.0566 D(x): 0.7374 D(G(z)): 0.1776 / 0.1529\n",
            "[1/500][193/625] Loss_D: 0.4786 Loss_G: 1.9699 D(x): 0.8076 D(G(z)): 0.2130 / 0.1595\n",
            "[1/500][194/625] Loss_D: 0.8134 Loss_G: 1.3303 D(x): 0.6452 D(G(z)): 0.2473 / 0.2884\n",
            "[1/500][195/625] Loss_D: 0.6603 Loss_G: 2.1979 D(x): 0.8059 D(G(z)): 0.3327 / 0.1220\n",
            "[1/500][196/625] Loss_D: 0.2544 Loss_G: 3.0586 D(x): 0.9002 D(G(z)): 0.1308 / 0.0610\n",
            "[1/500][197/625] Loss_D: 1.1658 Loss_G: 0.8151 D(x): 0.4752 D(G(z)): 0.2490 / 0.4838\n",
            "[1/500][198/625] Loss_D: 0.7725 Loss_G: 3.3559 D(x): 0.9649 D(G(z)): 0.4608 / 0.0552\n",
            "[1/500][199/625] Loss_D: 0.9459 Loss_G: 1.1700 D(x): 0.4866 D(G(z)): 0.1459 / 0.3567\n",
            "[1/500][200/625] Loss_D: 0.6258 Loss_G: 1.9676 D(x): 0.8482 D(G(z)): 0.3482 / 0.1536\n",
            "[1/500][201/625] Loss_D: 0.5538 Loss_G: 2.6938 D(x): 0.8374 D(G(z)): 0.2862 / 0.0820\n",
            "[1/500][202/625] Loss_D: 0.6825 Loss_G: 1.5698 D(x): 0.6415 D(G(z)): 0.1719 / 0.2407\n",
            "[1/500][203/625] Loss_D: 0.7668 Loss_G: 1.2785 D(x): 0.6857 D(G(z)): 0.2570 / 0.3106\n",
            "[1/500][204/625] Loss_D: 0.9773 Loss_G: 3.3771 D(x): 0.9000 D(G(z)): 0.5364 / 0.0426\n",
            "[1/500][205/625] Loss_D: 1.1205 Loss_G: 1.1567 D(x): 0.4604 D(G(z)): 0.1226 / 0.3488\n",
            "[1/500][206/625] Loss_D: 0.6087 Loss_G: 1.2061 D(x): 0.7359 D(G(z)): 0.2334 / 0.3231\n",
            "[1/500][207/625] Loss_D: 1.3946 Loss_G: 4.1958 D(x): 0.9386 D(G(z)): 0.6843 / 0.0238\n",
            "[1/500][208/625] Loss_D: 1.0735 Loss_G: 2.1969 D(x): 0.3936 D(G(z)): 0.0190 / 0.1372\n",
            "[1/500][209/625] Loss_D: 0.5852 Loss_G: 0.8817 D(x): 0.6923 D(G(z)): 0.1652 / 0.4547\n",
            "[1/500][210/625] Loss_D: 1.1459 Loss_G: 3.0462 D(x): 0.9566 D(G(z)): 0.6036 / 0.0563\n",
            "[1/500][211/625] Loss_D: 0.8080 Loss_G: 1.9955 D(x): 0.5782 D(G(z)): 0.1715 / 0.1775\n",
            "[1/500][212/625] Loss_D: 0.5962 Loss_G: 1.2890 D(x): 0.6813 D(G(z)): 0.1519 / 0.3007\n",
            "[1/500][213/625] Loss_D: 0.5962 Loss_G: 2.5800 D(x): 0.8931 D(G(z)): 0.3489 / 0.0878\n",
            "[1/500][214/625] Loss_D: 0.5036 Loss_G: 2.5012 D(x): 0.7602 D(G(z)): 0.1744 / 0.0990\n",
            "[1/500][215/625] Loss_D: 0.3322 Loss_G: 2.5046 D(x): 0.8498 D(G(z)): 0.1346 / 0.1020\n",
            "[1/500][216/625] Loss_D: 0.4482 Loss_G: 1.7153 D(x): 0.7576 D(G(z)): 0.1256 / 0.2106\n",
            "[1/500][217/625] Loss_D: 0.7351 Loss_G: 3.1156 D(x): 0.8825 D(G(z)): 0.4194 / 0.0523\n",
            "[1/500][218/625] Loss_D: 1.0371 Loss_G: 0.8628 D(x): 0.4844 D(G(z)): 0.1820 / 0.4351\n",
            "[1/500][219/625] Loss_D: 0.7197 Loss_G: 2.6143 D(x): 0.9037 D(G(z)): 0.4396 / 0.0794\n",
            "[1/500][220/625] Loss_D: 0.4183 Loss_G: 2.2376 D(x): 0.7115 D(G(z)): 0.0606 / 0.1170\n",
            "[1/500][221/625] Loss_D: 0.4598 Loss_G: 1.7015 D(x): 0.8082 D(G(z)): 0.1921 / 0.2057\n",
            "[1/500][222/625] Loss_D: 0.7630 Loss_G: 2.6667 D(x): 0.8081 D(G(z)): 0.3816 / 0.0864\n",
            "[1/500][223/625] Loss_D: 0.3609 Loss_G: 2.5684 D(x): 0.7862 D(G(z)): 0.1020 / 0.0970\n",
            "[1/500][224/625] Loss_D: 0.5895 Loss_G: 1.9778 D(x): 0.7498 D(G(z)): 0.2157 / 0.1805\n",
            "[1/500][225/625] Loss_D: 0.5529 Loss_G: 2.1360 D(x): 0.7738 D(G(z)): 0.2322 / 0.1387\n",
            "[1/500][226/625] Loss_D: 0.4075 Loss_G: 2.8103 D(x): 0.8526 D(G(z)): 0.1999 / 0.0714\n",
            "[1/500][227/625] Loss_D: 0.5122 Loss_G: 1.5355 D(x): 0.7122 D(G(z)): 0.1287 / 0.2502\n",
            "[1/500][228/625] Loss_D: 0.3170 Loss_G: 2.9509 D(x): 0.9392 D(G(z)): 0.2113 / 0.0659\n",
            "[1/500][229/625] Loss_D: 0.6242 Loss_G: 1.2648 D(x): 0.6821 D(G(z)): 0.1633 / 0.3297\n",
            "[1/500][230/625] Loss_D: 0.7827 Loss_G: 4.5827 D(x): 0.9333 D(G(z)): 0.4761 / 0.0119\n",
            "[1/500][231/625] Loss_D: 1.4433 Loss_G: 0.5624 D(x): 0.3050 D(G(z)): 0.0340 / 0.5818\n",
            "[1/500][232/625] Loss_D: 0.6595 Loss_G: 3.2430 D(x): 0.9686 D(G(z)): 0.4346 / 0.0451\n",
            "[1/500][233/625] Loss_D: 0.5005 Loss_G: 2.5715 D(x): 0.7512 D(G(z)): 0.1652 / 0.0962\n",
            "[1/500][234/625] Loss_D: 0.5960 Loss_G: 1.8965 D(x): 0.7632 D(G(z)): 0.2364 / 0.1757\n",
            "[1/500][235/625] Loss_D: 0.7499 Loss_G: 1.4267 D(x): 0.6721 D(G(z)): 0.2404 / 0.2955\n",
            "[1/500][236/625] Loss_D: 1.0961 Loss_G: 3.8020 D(x): 0.8207 D(G(z)): 0.5303 / 0.0316\n",
            "[1/500][237/625] Loss_D: 0.5437 Loss_G: 2.2999 D(x): 0.6666 D(G(z)): 0.0767 / 0.1280\n",
            "[1/500][238/625] Loss_D: 0.6319 Loss_G: 0.7034 D(x): 0.6156 D(G(z)): 0.0925 / 0.5552\n",
            "[1/500][239/625] Loss_D: 1.7032 Loss_G: 4.5057 D(x): 0.9902 D(G(z)): 0.7263 / 0.0165\n",
            "[1/500][240/625] Loss_D: 1.3246 Loss_G: 1.8866 D(x): 0.3617 D(G(z)): 0.0251 / 0.1823\n",
            "[1/500][241/625] Loss_D: 0.9051 Loss_G: 2.1191 D(x): 0.8141 D(G(z)): 0.4513 / 0.1415\n",
            "[1/500][242/625] Loss_D: 0.4205 Loss_G: 2.4138 D(x): 0.7608 D(G(z)): 0.1107 / 0.1187\n",
            "[1/500][243/625] Loss_D: 0.5801 Loss_G: 1.9059 D(x): 0.7908 D(G(z)): 0.2529 / 0.1716\n",
            "[1/500][244/625] Loss_D: 0.3898 Loss_G: 2.2777 D(x): 0.8325 D(G(z)): 0.1761 / 0.1254\n",
            "[1/500][245/625] Loss_D: 0.4275 Loss_G: 2.7941 D(x): 0.8913 D(G(z)): 0.2399 / 0.0698\n",
            "[1/500][246/625] Loss_D: 0.6189 Loss_G: 1.5482 D(x): 0.6647 D(G(z)): 0.1602 / 0.2329\n",
            "[1/500][247/625] Loss_D: 0.4956 Loss_G: 2.9532 D(x): 0.9256 D(G(z)): 0.3282 / 0.0597\n",
            "[1/500][248/625] Loss_D: 0.5419 Loss_G: 1.9904 D(x): 0.6697 D(G(z)): 0.0669 / 0.1712\n",
            "[1/500][249/625] Loss_D: 0.3744 Loss_G: 2.3720 D(x): 0.9082 D(G(z)): 0.2197 / 0.1079\n",
            "[1/500][250/625] Loss_D: 0.3556 Loss_G: 2.8715 D(x): 0.8597 D(G(z)): 0.1688 / 0.0807\n",
            "[1/500][251/625] Loss_D: 0.5878 Loss_G: 2.6344 D(x): 0.7871 D(G(z)): 0.2655 / 0.0943\n",
            "[1/500][252/625] Loss_D: 0.7677 Loss_G: 1.1393 D(x): 0.5984 D(G(z)): 0.1443 / 0.3846\n",
            "[1/500][253/625] Loss_D: 0.6490 Loss_G: 3.2315 D(x): 0.9442 D(G(z)): 0.4156 / 0.0496\n",
            "[1/500][254/625] Loss_D: 0.4729 Loss_G: 2.2807 D(x): 0.7035 D(G(z)): 0.0736 / 0.1187\n",
            "[1/500][255/625] Loss_D: 0.4515 Loss_G: 1.4869 D(x): 0.7526 D(G(z)): 0.1284 / 0.2801\n",
            "[1/500][256/625] Loss_D: 0.8386 Loss_G: 3.7026 D(x): 0.9284 D(G(z)): 0.4717 / 0.0317\n",
            "[1/500][257/625] Loss_D: 0.9243 Loss_G: 1.5611 D(x): 0.5256 D(G(z)): 0.0656 / 0.2652\n",
            "[1/500][258/625] Loss_D: 0.3048 Loss_G: 1.8856 D(x): 0.8773 D(G(z)): 0.1421 / 0.1840\n",
            "[1/500][259/625] Loss_D: 0.9424 Loss_G: 5.0898 D(x): 0.9375 D(G(z)): 0.5284 / 0.0084\n",
            "[1/500][260/625] Loss_D: 1.7393 Loss_G: 0.7534 D(x): 0.2582 D(G(z)): 0.0311 / 0.5595\n",
            "[1/500][261/625] Loss_D: 1.1915 Loss_G: 4.4919 D(x): 0.9560 D(G(z)): 0.6168 / 0.0147\n",
            "[1/500][262/625] Loss_D: 1.7981 Loss_G: 0.4373 D(x): 0.2344 D(G(z)): 0.0394 / 0.6864\n",
            "[1/500][263/625] Loss_D: 1.9556 Loss_G: 3.9764 D(x): 0.9854 D(G(z)): 0.7804 / 0.0317\n",
            "[1/500][264/625] Loss_D: 0.5125 Loss_G: 3.2447 D(x): 0.6978 D(G(z)): 0.1037 / 0.0506\n",
            "[1/500][265/625] Loss_D: 1.1363 Loss_G: 0.5358 D(x): 0.4415 D(G(z)): 0.1026 / 0.6064\n",
            "[1/500][266/625] Loss_D: 1.2901 Loss_G: 2.8044 D(x): 0.9513 D(G(z)): 0.6044 / 0.0914\n",
            "[1/500][267/625] Loss_D: 0.9743 Loss_G: 2.0923 D(x): 0.5925 D(G(z)): 0.2377 / 0.1390\n",
            "[1/500][268/625] Loss_D: 0.5589 Loss_G: 1.9260 D(x): 0.7514 D(G(z)): 0.1918 / 0.1673\n",
            "[1/500][269/625] Loss_D: 0.6494 Loss_G: 1.9651 D(x): 0.7513 D(G(z)): 0.2586 / 0.1699\n",
            "[1/500][270/625] Loss_D: 0.5805 Loss_G: 1.5414 D(x): 0.7004 D(G(z)): 0.1694 / 0.2372\n",
            "[1/500][271/625] Loss_D: 0.5223 Loss_G: 2.7068 D(x): 0.8970 D(G(z)): 0.3058 / 0.0883\n",
            "[1/500][272/625] Loss_D: 0.5424 Loss_G: 2.4294 D(x): 0.7633 D(G(z)): 0.2041 / 0.1070\n",
            "[1/500][273/625] Loss_D: 0.6624 Loss_G: 1.8881 D(x): 0.7135 D(G(z)): 0.2195 / 0.1745\n",
            "[1/500][274/625] Loss_D: 0.7393 Loss_G: 1.0555 D(x): 0.6340 D(G(z)): 0.2071 / 0.3716\n",
            "[1/500][275/625] Loss_D: 0.9510 Loss_G: 2.9822 D(x): 0.8815 D(G(z)): 0.5165 / 0.0698\n",
            "[1/500][276/625] Loss_D: 1.1337 Loss_G: 0.8706 D(x): 0.3944 D(G(z)): 0.0835 / 0.4471\n",
            "[1/500][277/625] Loss_D: 0.6986 Loss_G: 2.5311 D(x): 0.9725 D(G(z)): 0.4636 / 0.0887\n",
            "[1/500][278/625] Loss_D: 0.7626 Loss_G: 4.3321 D(x): 0.9061 D(G(z)): 0.4474 / 0.0150\n",
            "[1/500][279/625] Loss_D: 1.7633 Loss_G: 1.2143 D(x): 0.2183 D(G(z)): 0.0159 / 0.3246\n",
            "[1/500][280/625] Loss_D: 0.7400 Loss_G: 1.5597 D(x): 0.8720 D(G(z)): 0.3973 / 0.2381\n",
            "[1/500][281/625] Loss_D: 0.4987 Loss_G: 3.2115 D(x): 0.9220 D(G(z)): 0.3250 / 0.0476\n",
            "[1/500][282/625] Loss_D: 0.8493 Loss_G: 1.3820 D(x): 0.5597 D(G(z)): 0.1768 / 0.3080\n",
            "[1/500][283/625] Loss_D: 0.8467 Loss_G: 1.8125 D(x): 0.7678 D(G(z)): 0.3673 / 0.2030\n",
            "[1/500][284/625] Loss_D: 0.6798 Loss_G: 2.7477 D(x): 0.7937 D(G(z)): 0.3130 / 0.0778\n",
            "[1/500][285/625] Loss_D: 0.7169 Loss_G: 1.3572 D(x): 0.6039 D(G(z)): 0.1397 / 0.2912\n",
            "[1/500][286/625] Loss_D: 0.6352 Loss_G: 2.4990 D(x): 0.8808 D(G(z)): 0.3773 / 0.0887\n",
            "[1/500][287/625] Loss_D: 0.8210 Loss_G: 1.9681 D(x): 0.6318 D(G(z)): 0.2429 / 0.1803\n",
            "[1/500][288/625] Loss_D: 0.6628 Loss_G: 1.6212 D(x): 0.7135 D(G(z)): 0.1988 / 0.2209\n",
            "[1/500][289/625] Loss_D: 0.8623 Loss_G: 2.4107 D(x): 0.7934 D(G(z)): 0.4168 / 0.1196\n",
            "[1/500][290/625] Loss_D: 0.6121 Loss_G: 2.3880 D(x): 0.6920 D(G(z)): 0.1668 / 0.1183\n",
            "[1/500][291/625] Loss_D: 0.5980 Loss_G: 1.3721 D(x): 0.6870 D(G(z)): 0.1398 / 0.2907\n",
            "[1/500][292/625] Loss_D: 0.4331 Loss_G: 2.5114 D(x): 0.9205 D(G(z)): 0.2827 / 0.0904\n",
            "[1/500][293/625] Loss_D: 0.4780 Loss_G: 2.8062 D(x): 0.8367 D(G(z)): 0.2382 / 0.0679\n",
            "[1/500][294/625] Loss_D: 0.9863 Loss_G: 0.7205 D(x): 0.4850 D(G(z)): 0.0760 / 0.5136\n",
            "[1/500][295/625] Loss_D: 1.2146 Loss_G: 3.6613 D(x): 0.9434 D(G(z)): 0.6365 / 0.0330\n",
            "[1/500][296/625] Loss_D: 0.8035 Loss_G: 1.6714 D(x): 0.5351 D(G(z)): 0.0838 / 0.2303\n",
            "[1/500][297/625] Loss_D: 0.9352 Loss_G: 2.2080 D(x): 0.7902 D(G(z)): 0.4242 / 0.1382\n",
            "[1/500][298/625] Loss_D: 0.3852 Loss_G: 2.5604 D(x): 0.8172 D(G(z)): 0.1563 / 0.0831\n",
            "[1/500][299/625] Loss_D: 0.5704 Loss_G: 1.3637 D(x): 0.6663 D(G(z)): 0.0959 / 0.2950\n",
            "[1/500][300/625] Loss_D: 0.7221 Loss_G: 3.1347 D(x): 0.9210 D(G(z)): 0.4418 / 0.0522\n",
            "[1/500][301/625] Loss_D: 0.5945 Loss_G: 1.6847 D(x): 0.6541 D(G(z)): 0.1264 / 0.2088\n",
            "[1/500][302/625] Loss_D: 0.4305 Loss_G: 1.9535 D(x): 0.8168 D(G(z)): 0.1881 / 0.1779\n",
            "[1/500][303/625] Loss_D: 0.5453 Loss_G: 2.6145 D(x): 0.8454 D(G(z)): 0.2889 / 0.0909\n",
            "[1/500][304/625] Loss_D: 0.7154 Loss_G: 1.7237 D(x): 0.6620 D(G(z)): 0.1699 / 0.2300\n",
            "[1/500][305/625] Loss_D: 0.4135 Loss_G: 2.0667 D(x): 0.8259 D(G(z)): 0.1841 / 0.1413\n",
            "[1/500][306/625] Loss_D: 0.5468 Loss_G: 3.6142 D(x): 0.9161 D(G(z)): 0.3353 / 0.0338\n",
            "[1/500][307/625] Loss_D: 0.7517 Loss_G: 0.9261 D(x): 0.5261 D(G(z)): 0.0627 / 0.4285\n",
            "[1/500][308/625] Loss_D: 0.6120 Loss_G: 2.4549 D(x): 0.9335 D(G(z)): 0.3900 / 0.1038\n",
            "[1/500][309/625] Loss_D: 0.5940 Loss_G: 2.2447 D(x): 0.7433 D(G(z)): 0.2177 / 0.1206\n",
            "[1/500][310/625] Loss_D: 0.8385 Loss_G: 1.4644 D(x): 0.6409 D(G(z)): 0.2432 / 0.2550\n",
            "[1/500][311/625] Loss_D: 0.6147 Loss_G: 3.0084 D(x): 0.8769 D(G(z)): 0.3455 / 0.0601\n",
            "[1/500][312/625] Loss_D: 0.6805 Loss_G: 1.5691 D(x): 0.6480 D(G(z)): 0.1329 / 0.2308\n",
            "[1/500][313/625] Loss_D: 0.3162 Loss_G: 2.4343 D(x): 0.9004 D(G(z)): 0.1682 / 0.0985\n",
            "[1/500][314/625] Loss_D: 0.5822 Loss_G: 3.2232 D(x): 0.8578 D(G(z)): 0.3217 / 0.0486\n",
            "[1/500][315/625] Loss_D: 0.6350 Loss_G: 1.5031 D(x): 0.6321 D(G(z)): 0.0785 / 0.2593\n",
            "[1/500][316/625] Loss_D: 0.5775 Loss_G: 1.4304 D(x): 0.7855 D(G(z)): 0.2629 / 0.2662\n",
            "[1/500][317/625] Loss_D: 0.5905 Loss_G: 3.1625 D(x): 0.8897 D(G(z)): 0.3594 / 0.0470\n",
            "[1/500][318/625] Loss_D: 0.5547 Loss_G: 2.1625 D(x): 0.6983 D(G(z)): 0.1317 / 0.1364\n",
            "[1/500][319/625] Loss_D: 0.3910 Loss_G: 2.0271 D(x): 0.8031 D(G(z)): 0.1474 / 0.1683\n",
            "[1/500][320/625] Loss_D: 0.4961 Loss_G: 2.7229 D(x): 0.8593 D(G(z)): 0.2570 / 0.0816\n",
            "[1/500][321/625] Loss_D: 0.4230 Loss_G: 2.2481 D(x): 0.7789 D(G(z)): 0.1455 / 0.1195\n",
            "[1/500][322/625] Loss_D: 0.5336 Loss_G: 1.5998 D(x): 0.7253 D(G(z)): 0.1432 / 0.2435\n",
            "[1/500][323/625] Loss_D: 0.6062 Loss_G: 4.0314 D(x): 0.9235 D(G(z)): 0.3848 / 0.0208\n",
            "[1/500][324/625] Loss_D: 0.8102 Loss_G: 1.0496 D(x): 0.4949 D(G(z)): 0.0341 / 0.4363\n",
            "[1/500][325/625] Loss_D: 1.0279 Loss_G: 4.6598 D(x): 0.9428 D(G(z)): 0.5818 / 0.0118\n",
            "[1/500][326/625] Loss_D: 1.4257 Loss_G: 0.6440 D(x): 0.3016 D(G(z)): 0.0315 / 0.5556\n",
            "[1/500][327/625] Loss_D: 1.5649 Loss_G: 5.1803 D(x): 0.9384 D(G(z)): 0.7318 / 0.0066\n",
            "[1/500][328/625] Loss_D: 1.2087 Loss_G: 0.9030 D(x): 0.3746 D(G(z)): 0.0162 / 0.4490\n",
            "[1/500][329/625] Loss_D: 0.8137 Loss_G: 1.9698 D(x): 0.8509 D(G(z)): 0.4169 / 0.1774\n",
            "[1/500][330/625] Loss_D: 0.5090 Loss_G: 3.1563 D(x): 0.8716 D(G(z)): 0.2744 / 0.0550\n",
            "[1/500][331/625] Loss_D: 0.5366 Loss_G: 2.5199 D(x): 0.7549 D(G(z)): 0.1937 / 0.1033\n",
            "[1/500][332/625] Loss_D: 0.5008 Loss_G: 2.0474 D(x): 0.7470 D(G(z)): 0.1645 / 0.1665\n",
            "[1/500][333/625] Loss_D: 0.5187 Loss_G: 2.2369 D(x): 0.7976 D(G(z)): 0.2064 / 0.1608\n",
            "[1/500][334/625] Loss_D: 0.3427 Loss_G: 2.4741 D(x): 0.8644 D(G(z)): 0.1622 / 0.1024\n",
            "[1/500][335/625] Loss_D: 0.5481 Loss_G: 2.3374 D(x): 0.7993 D(G(z)): 0.2529 / 0.1143\n",
            "[1/500][336/625] Loss_D: 0.5558 Loss_G: 1.5541 D(x): 0.6946 D(G(z)): 0.1353 / 0.2435\n",
            "[1/500][337/625] Loss_D: 0.4108 Loss_G: 2.4536 D(x): 0.9012 D(G(z)): 0.2407 / 0.1031\n",
            "[1/500][338/625] Loss_D: 0.5839 Loss_G: 2.3268 D(x): 0.7819 D(G(z)): 0.2205 / 0.1273\n",
            "[1/500][339/625] Loss_D: 0.4603 Loss_G: 2.1940 D(x): 0.8194 D(G(z)): 0.1933 / 0.1228\n",
            "[1/500][340/625] Loss_D: 0.5056 Loss_G: 2.4936 D(x): 0.8082 D(G(z)): 0.2316 / 0.0955\n",
            "[1/500][341/625] Loss_D: 0.8584 Loss_G: 0.7769 D(x): 0.5397 D(G(z)): 0.1441 / 0.5066\n",
            "[1/500][342/625] Loss_D: 1.2225 Loss_G: 4.2880 D(x): 0.9460 D(G(z)): 0.6414 / 0.0152\n",
            "[1/500][343/625] Loss_D: 1.1242 Loss_G: 1.4631 D(x): 0.3937 D(G(z)): 0.0374 / 0.3044\n",
            "[1/500][344/625] Loss_D: 0.6365 Loss_G: 2.3481 D(x): 0.8838 D(G(z)): 0.3509 / 0.1503\n",
            "[1/500][345/625] Loss_D: 0.6143 Loss_G: 3.1985 D(x): 0.8465 D(G(z)): 0.3004 / 0.0569\n",
            "[1/500][346/625] Loss_D: 0.3422 Loss_G: 2.8183 D(x): 0.8002 D(G(z)): 0.0827 / 0.0826\n",
            "[1/500][347/625] Loss_D: 0.4938 Loss_G: 1.8267 D(x): 0.7242 D(G(z)): 0.1170 / 0.2212\n",
            "[1/500][348/625] Loss_D: 0.7506 Loss_G: 2.9258 D(x): 0.8562 D(G(z)): 0.3945 / 0.0702\n",
            "[1/500][349/625] Loss_D: 0.4409 Loss_G: 3.6516 D(x): 0.8573 D(G(z)): 0.2225 / 0.0372\n",
            "[1/500][350/625] Loss_D: 0.8433 Loss_G: 1.1970 D(x): 0.4918 D(G(z)): 0.0245 / 0.3554\n",
            "[1/500][351/625] Loss_D: 0.6041 Loss_G: 2.5854 D(x): 0.9538 D(G(z)): 0.3975 / 0.0926\n",
            "[1/500][352/625] Loss_D: 0.3938 Loss_G: 3.6386 D(x): 0.8952 D(G(z)): 0.2301 / 0.0358\n",
            "[1/500][353/625] Loss_D: 0.6464 Loss_G: 2.1465 D(x): 0.7015 D(G(z)): 0.1850 / 0.1392\n",
            "[1/500][354/625] Loss_D: 0.7215 Loss_G: 1.5944 D(x): 0.6334 D(G(z)): 0.1297 / 0.2754\n",
            "[1/500][355/625] Loss_D: 1.0674 Loss_G: 3.8495 D(x): 0.9473 D(G(z)): 0.5816 / 0.0260\n",
            "[1/500][356/625] Loss_D: 1.6294 Loss_G: 0.6624 D(x): 0.2632 D(G(z)): 0.0454 / 0.5571\n",
            "[1/500][357/625] Loss_D: 0.9164 Loss_G: 2.9320 D(x): 0.9532 D(G(z)): 0.5127 / 0.0805\n",
            "[1/500][358/625] Loss_D: 0.4887 Loss_G: 2.1511 D(x): 0.7206 D(G(z)): 0.0996 / 0.1388\n",
            "[1/500][359/625] Loss_D: 0.8983 Loss_G: 0.9316 D(x): 0.5984 D(G(z)): 0.2359 / 0.4272\n",
            "[1/500][360/625] Loss_D: 0.7507 Loss_G: 3.4281 D(x): 0.9546 D(G(z)): 0.4462 / 0.0406\n",
            "[1/500][361/625] Loss_D: 0.5841 Loss_G: 3.2963 D(x): 0.7773 D(G(z)): 0.2261 / 0.0494\n",
            "[1/500][362/625] Loss_D: 0.6701 Loss_G: 1.2805 D(x): 0.6149 D(G(z)): 0.0589 / 0.3076\n",
            "[1/500][363/625] Loss_D: 1.1085 Loss_G: 2.7642 D(x): 0.8385 D(G(z)): 0.5337 / 0.0805\n",
            "[1/500][364/625] Loss_D: 0.8039 Loss_G: 0.9398 D(x): 0.5267 D(G(z)): 0.0921 / 0.4171\n",
            "[1/500][365/625] Loss_D: 0.8536 Loss_G: 3.4509 D(x): 0.9441 D(G(z)): 0.4924 / 0.0397\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-4fe6bc982ebb>\u001b[0m in \u001b[0;36m<cell line: 90>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-4fe6bc982ebb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_cpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0merrD_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0merrD_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mD_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "这是跑出来的效果![real_samples.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "WHQu9fwdV4wX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "任务二"
      ],
      "metadata": {
        "id": "zfP5190CVIqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# 1. 加载CIFAR-10数据集\n",
        "(x_train, _), (_, _) = cifar10.load_data()\n",
        "x_train = x_train / 127.5 - 1.0  # 归一化到[-1, 1]范围\n",
        "x_train = x_train.astype(\"float32\")\n",
        "\n",
        "# 2. 定义生成器模型\n",
        "def build_generator():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(8 * 8 * 256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Reshape((8, 8, 256)))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding=\"same\", use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(3, (3, 3), padding=\"same\", activation=\"tanh\"))\n",
        "    return model\n",
        "\n",
        "# 3. 定义判别器模型\n",
        "def build_discriminator():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\", input_shape=[32, 32, 3]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "    return model\n",
        "\n",
        "# 4. 创建生成器和判别器实例\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "# 5. 定义损失函数和优化器\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "# 6. 定义训练过程\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([batch_size, 100])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "# 7. 设置训练循环\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        for image_batch in dataset:\n",
        "            train_step(image_batch)\n",
        "\n",
        "        # 每隔一定周期显示生成的图片\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch {epoch + 1}, Time: {time.time() - start}')\n",
        "\n",
        "# 8. 数据集准备与模型训练\n",
        "buffer_size = 50000\n",
        "batch_size = 256\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(buffer_size).batch(batch_size)\n",
        "\n",
        "epochs = 100\n",
        "train(train_dataset, epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "j9sq3BlSVKu8",
        "outputId": "0ebe7ebf-49b2-4056-809f-72f0b0717f80"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-e9c1e16bd382>\u001b[0m in \u001b[0;36m<cell line: 104>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-e9c1e16bd382>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# 每隔一定周期显示生成的图片\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    870\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}